% AML bibtex
%
@phdthesis{SeppiDisteration1990,
 author = {Kevin Darrell Seppi},
 title = {A Bayesian Approach to Selected Database Issues},
 year = {1990},
 note = {AAI9105658},
  school       = {The University of Texas},
 publisher = {The University of Texas at Austin},
  address      = {Austin, Texas},
  month        = {August},
 abstract = {Relational database system users retrieve data by specifying what they want, not how it should be found. A 'query optimizer' is responsible for determining how the desired data will be found. For each step in a query there may exist several candidate algorithms which could be used to perform the required operation. The execution times for these algorithms depend on the statistical properties of the user data to be processed, and may differ widely. The execution cost of each algorithm is estimated using statistics on the user data and cost models. The algorithm with lowest estimated cost is used.
This decision process is subject to error. Bayesian decision theory is used here to quantify the expected improvement in the decision if the choice of algorithm were postponed until additional information is acquired. The expected value of additional information is compared with the information acquisition cost before the additional information is actually acquired. Additional information, gained from sources like sampled user data, should be obtained whenever it is expected to yield a significant net reduction in execution time.
Computational methods for determining the expected value of sample information (EVSI) are explored. These methods allow for the application of these concepts to a wide range of query optimization problems. Three such problems in database query optimization are presented with example computations of the expected value of sample information.},
tags = {kevinseppi}
}

@article{HumanTouch2017,
title = {The human touch: How non-expert users perceive, interpret, and fix topic models},
journal = {International Journal of Human-Computer Studies},
volume = {105},
pages = {28--42},
year = {2017},
issn = {1071-5819},
doi = {10.1016/j.ijhcs.2017.03.007},
url = {http://www.sciencedirect.com/science/article/pii/S1071581917300472},
author = {Tak Yeon Lee and Alison Smith and Kevin Seppi and Niklas Elmqvist and Jordan Boyd-Graber and Leah Findlater},
keywords = {Topic modeling},
keywords = {User study},
keywords = {Mixed-initiative interaction},
abstract = {Abstract Topic modeling is a common tool for understanding large bodies of text, but is typically provided as a “take it or leave it” proposition. Incorporating human knowledge in unsupervised learning is a promising approach to create high-quality topic models. Existing interactive systems and modeling algorithms support a wide range of refinement operations to express feedback. However, these systems’ interactions are primarily driven by algorithmic convenience, ignoring users who may lack expertise in topic modeling. To better understand how non-expert users understand, assess, and refine topics, we conducted two user studies—an in-person interview study and an online crowdsourced study. These studies demonstrate a disconnect between what non-expert users want and the complex, low-level operations that current interactive systems support. In particular, our findings include: (1) analysis of how non-expert users perceive topic models; (2) characterization of primary refinement operations expected by non-expert users and ordered by relative preference; (3) further evidence of the benefits of supporting users in directly refining a topic model; (4) design implications for future human-in-the-loop topic modeling interfaces.},
tags = {closingtheloop , kevinseppi}
}

@ARTICLE{Replication2016, 
author={J. L. Krein and L. Prechelt and N. Juristo and A. Nanthaamornphong and J. C. Carver and S. Vegas and C. D. Knutson and K. D. Seppi and D. L. Eggett}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Multi-Site Joint Replication of a Design Patterns Experiment Using Moderator Variables to Generalize across Contexts}, 
year={2016}, 
volume={42}, 
number={4}, 
pages={302-321}, 
abstract={Context. Several empirical studies have explored the benefits of software design patterns, but their collective results are highly inconsistent. Resolving the inconsistencies requires investigating moderators—i.e., variables that cause an effect to differ across contexts. Objectives. Replicate a design patterns experiment at multiple sites and identify sufficient moderators to generalize the results across prior studies. Methods. We perform a close replication of an experiment investigating the impact (in terms of time and quality) of design patterns (Decorator and Abstract Factory) on software maintenance. The experiment was replicated once previously, with divergent results. We execute our replication at four universities—spanning two continents and three countries—using a new method for performing distributed replications based on closely coordinated, small-scale instances (“joint replication”). We perform two analyses: 1) a post-hoc analysis of moderators, based on frequentist and Bayesian statistics; 2) an a priori analysis of the original hypotheses, based on frequentist statistics. Results. The main effect differs across the previous instances of the experiment and across the sites in our distributed replication. Our analysis of moderators (including developer experience and pattern knowledge) resolves the differences sufficiently to allow for cross-context (and cross-study) conclusions. The final conclusions represent 126 participants from five universities and 12 software companies, spanning two continents and at least four countries. Conclusions. The Decorator pattern is found to be preferable to a simpler solution during maintenance, as long as the developer has at least some prior knowledge of the pattern. For A- stract Factory, the simpler solution is found to be mostly equivalent to the pattern solution. Abstract Factory is shown to require a higher level of knowledge and/or experience than Decorator for the pattern to be beneficial.}, 
keywords={Context modeling;Design methodology;Production facilities;Training;Design patterns;controlled experiment;joint replication;moderator variables;multi-site;software maintenance}, 
doi={10.1109/TSE.2015.2488625}, 
ISSN={0098-5589}, 
month={April},
tags = {kevinseppi}
}

@Article{UrbanTracking2014,
author="Cook, Kevin
and Bryan, Everett
and Yu, Huili
and Bai, He
and Seppi, Kevin
and Beard, Randal",
title="Intelligent Cooperative Control for Urban Tracking",
journal="Journal of Intelligent {\&} Robotic Systems",
issue_date = {April 2014},
year={2014},
month = {April},
volume = {74},
number = {1-2},
issn = {0921-0296},
pages = {251--267},
numpages = {17},
issn="1573-0409",
doi="10.1007/s10846-013-9896-5",
url="http://dx.doi.org/10.1007/s10846-013-9896-5",
acmid = {2590011},
publisher = {Kluwer Academic Publishers},
address = {Hingham, MA, USA},
keywords = {Cooperative control, Intelligent, Learning, Target tracking, UAVs, Urban tracking},
abstract="We introduce an intelligent cooperative control system for ground target tracking in a cluttered urban environment with a team of autonomous Unmanned Air Vehicles (UAVs). We extend the work of Yu et al. to use observations of target position to learn a model of target motion. Simulated cooperative control of a team of 9 UAVs in a 100-block city filled with various sizes of buildings verifies that learning a model of target motion can improve target tracking performance.",
tags = {intelligenttracking,kevinseppi}
}

@Article{UnderResourced2014,
author="Felt, Paul
and Ringger, Eric K.
and Seppi, Kevin
and Heal, Kristian S.
and Haertel, Robbie A.
and Lonsdale, Deryle",
title="Evaluating machine-assisted annotation in under-resourced settings",
journal="Language Resources and Evaluation",
year="2014",
issue_date = {December  2014},
volume = {48},
number = {4},
month = dec,
year = {2014},
issn = {1574-020X},
pages = {561--599},
numpages = {39},
url = {http://dx.doi.org/10.1007/s10579-013-9258-8},
issn="1574-0218",
doi = {10.1007/s10579-013-9258-8},
acmid = {2693489},
publisher = {Springer-Verlag New York, Inc.},
address = {Secaucus, NJ, USA},
keywords = {Annotation, Bayesian data analysis, Corpus annotation, Language resource evaluation, Machine assistance, Syriac studies, User study},
abstract="Machine assistance is vital to managing the cost of corpus annotation projects. Identifying effective forms of machine assistance through principled evaluation is particularly important and challenging in under-resourced domains and highly heterogeneous corpora, as the quality of machine assistance varies. We perform a fine-grained evaluation of two machine-assistance techniques in the context of an under-resourced corpus annotation project. This evaluation requires a carefully controlled user study crafted to test a number of specific hypotheses. We show that human annotators performing morphological analysis of text in a Semitic language perform their task significantly more accurately and quickly when even mediocre pre-annotations are provided. When pre-annotations are at least 70 {\%} accurate, annotator speed and accuracy show statistically significant relative improvements of 25--35 and 5--7 {\%}, respectively. However, controlled user studies are too costly to be suitable for under-resourced corpus annotation projects. Thus, we also present an alternative analysis methodology that models the data as a combination of latent variables in a Bayesian framework. We show that modeling the effects of interesting confounding factors can generate useful insights. In particular, correction propagation appears to be most effective for our task when implemented with minimal user involvement. More importantly, by explicitly accounting for confounding variables, this approach has the potential to yield fine-grained evaluations using data collected in a natural environment outside of costly controlled user studies.",
tags = {kevinseppi}
}



@Article{Speculative2012,
author="Gardner, Matthew
and McNabb, Andrew
and Seppi, Kevin",
title="A speculative approach to parallelization in particle swarm optimization",
journal="Swarm Intelligence",
year="2012",
volume="6",
number="2",
pages="77--116",
abstract="Particle swarm optimization (PSO) has previously been parallelized primarily by distributing the computation corresponding to particles across multiple processors. In these approaches, the only benefit of additional processors is an increased swarm size. However, in many cases this is not efficient when scaled to very large swarm sizes (on very large clusters). Current methods cannot answer well the question: ``How can 1000 processors be fully utilized when 50 or 100 particles is the most efficient swarm size?'' In this paper we attempt to answer that question with a speculative approach to the parallelization of PSO that we refer to as SEPSO.",
issn="1935-3820",
doi="10.1007/s11721-011-0066-8",
url="http://dx.doi.org/10.1007/s11721-011-0066-8",
tags = {kevinseppi , matthewgardner, andrewmcnabb}
}


@article{GraphicalOptimization2008,
author = { Christopher K. Monson and  Kevin D. Seppi},
title = {A Graphical Model for Evolutionary Optimization},
journal = {Evolutionary Computation},
 issue_date = {Fall 2008},
volume = {16},
number = {3},
pages = {289-313},
 numpages = {25},
year = {2008},
 month = {September},
doi = {10.1162/evco.2008.16.3.289},
 issn = {1063-6560},
 acmid = {1450301},
note ={PMID: 18811244},
URL = {http://dx.doi.org/10.1162/evco.2008.16.3.289},
eprint = {http://dx.doi.org/10.1162/evco.2008.16.3.289},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 keywords = {Mathematical optimization models, estimation of distribution algorithms, evolutionary optimization},
  timestamp = {Thu, 18 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/ec/MonsonS08},
  bibsource = {dblp computer science bibliography, http://dblp.org},
    abstract = { Abstract We present a statistical model of empirical optimization that admits the creation of algorithms with explicit and intuitively defined desiderata. Because No Free Lunch theorems dictate that no optimization algorithm can be considered more efficient than any other when considering all possible functions, the desired function class plays a prominent role in the model. In particular, this provides a direct way to answer the traditionally difficult question of what algorithm is best matched to a particular class of functions. Among the benefits of the model are the ability to specify the function class in a straightforward manner, a natural way to specify noisy or dynamic functions, and a new source of insight into No Free Lunch theorems for optimization. },
tags = {christophermonson , kevinseppi}
}

@article{Jumpstart2006,
 title = {Jumpstarting Phylogenetic Analysis},
  author    = {Jesse Mecham and
               Mark J. Clement and
               Quinn Snell and
               Todd Freestone and
               Kevin D. Seppi and
               Keith A. Crandall},
journal={International Journal of Bioinformatics Research and Applications, {IJBRA}},
 issue_date = {March 2006},
volume={2},
number={1},
pages={19--35},
 numpages = {17},
year={2006},
 month = mar,
publisher={Inderscience Publishers},
doi = {10.1504/IJBRA.2006.009191},
URL = {https://doi.org/10.1504/IJBRA.2006.009191},
 issn = {1744-5485},
 acmid = {1356590},
 publisher = {Inderscience Publishers},
 address = {Inderscience Publishers, Geneva, SWITZERLAND},
 keywords = {DNA, alignment, bioinformatics, comparative genomics, jumpstarting algorithm, large data sets, phylogenetic analysis, phylogenetic search, phylogenetics},
  timestamp = {Thu, 15 Jun 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/ijbra/MechamCSFSC06},
  bibsource = {dblp computer science bibliography, http://dblp.org},
abstract={Phylogenetic analysis is a central tool in studies of comparative
genomics. When a new region of DNA is isolated and sequenced, researchers
are often forced to throw away months of computation on an existing
phylogeny of homologous sequences in order to incorporate this new sequence.
The previously constructed trees are often discarded, and the researcher begins
the search again from scratch. The jumpstarting algorithm uses trees from the
prior search as a starting point for a new phylogenetic search. This technique
drastically decreases search time for large data sets. This kind of analysis is
necessary as researchers analyse tree of life size data sets.  },
tags = {kevinseppi}
}

@article{BayesianModelChecking2006,
  author    = {Kevin D. Seppi and
               Michael D. Jones and
               Peter Lamborn},
 title = {Guided Model Checking with a Bayesian Meta-heuristic},
 journal = {Fundamenta Informaticae},
 issue_date = {April 2006},
 volume = {70},
 number = {1-2},
 month = apr,
 year = {2006},
 issn = {0169-2968},
 pages = {111--126},
 numpages = {16},
 url = {http://dl.acm.org/citation.cfm?id=2367636.2367641},
 acmid = {2367641},
 publisher = {IOS Press},
 address = {Amsterdam, The Netherlands, The Netherlands},
  timestamp = {Mon, 18 May 2015 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/fuin/SeppiJL06},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 abstract = {This paper presents a meta-heuristic for use in finding errors in models of complex concurrent systems using explicit guided model checking. The meta-heuristic improves explicit guided model checking by applying the empirical Bayes method to revise heuristic estimates of the distance from a given state to an error state. Guided search using the revised estimates finds errors with less search effort than the original estimates.},
tags = {kevinseppi}
} 
%  url       = {http://content.iospress.com/articles/fundamenta-informaticae/fi70-1-2-06},

@article{MDPPrioritization2005,
  title={Prioritization methods for accelerating MDP solvers},
  author={Wingate, David and Seppi, Kevin D},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={851--881},
 numpages = {31},
  year={2005},
 month = dec,
 issn = {1532-4435},
 acmid = {1088701},
 publisher = {JMLR.org},
  abstract={ The performance of value and policy iteration can be dramatically improved by eliminating redundant
or useless backups, and by backing up states in the right order. We study several methods
designed to accelerate these iterative solvers, including prioritization, partitioning, and variable
reordering. We generate a family of algorithms by combining several of the methods discussed,
and present extensive empirical evidence demonstrating that performance can improve by several
orders of magnitude for many problems, while preserving accuracy and convergence guarantees.},
  keywords = {Markov Decision Processes, value iteration, policy iteration, prioritized sweeping,
dynamic programming},
  url={http://www.jmlr.org/papers/v6/wingate05a.html},
tags = {kevinseppi}
}
% url = {http://dl.acm.org/citation.cfm?id=1046920.1088701},


@article{BayesianQueryOptimization1993,
author = {Kevin D. Seppi and J. Wesley Barnes and Carl N. Morris},
title = {A Bayesian Approach to Database Query Optimization},
journal = {{ORSA} (now {INFORMS}) Journal on Computing},
volume = {5},
number = {4},
pages = {410--419},
year = {1993},
doi = {10.1287/ijoc.5.4.410},
url = {https://doi.org/10.1287/ijoc.5.4.410},
eprint = {https://doi.org/10.1287/ijoc.5.4.410},
timestamp = {Sun, 28 May 2017 01:00:00 +0200},
biburl    = {http://dblp.uni-trier.de/rec/bib/journals/informs/SeppiBM93},
bibsource = {dblp computer science bibliography, http://dblp.org},
abstract = { The focus of this paper is the application of Bayesian concepts to database query optimization. In relational database systems users retrieve data by describing the desired data. The description of the desired data takes the form of statements which specify operations on “relations” (as defined by set theory). In a relational database system a “query optimizer” determines how the desired data is to be found. The optimizer may have access to several potential algorithms for each step in the query. Each algorithm has a unique effect on the cost of evaluating the query. No single algorithm is best in all cases. To choose among the possible alternatives, the optimizer uses summary statistics of the data stored in the database to estimate the cost associated with the use of each alternative algorithm. Given the summary nature of the statistics typically collected, the true cost of the use of a given algorithm can be only estimated. As such, the query optimizer must choose algorithms in the presence of uncertainty. As will be illustrated later with a simple model, cases exist where the expected improvement in decision quality more than offsets the cost of sampling the database to gathering additional, more accurate, information. These cases are identified before such sampling is performed by using Bayesian pre-posterier analysis. When sample information is expected to have significant net value to the decision making process, sampling should be performed. In database query optimization readily available summary information is sufficient for the decision making process in some cases, in other cases, it is wholly inadequate. Examples of each of these cases will be identified. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499. }
}

@article{HiddenLine1983,
author = {Kevin D. Seppi},
title = {Simplified hidden Line Removal},
journal = {Journal of Pascal and Ada},
volume = {2},
number = {1},
year = {1983},
url={https://books.google.com/books?id=d0UsAQAAIAAJ},
publisher={Bayes Publishing Company}
}

% Conferences:

@inproceedings{OutdoorRec2017,
  author    = {Michael D. Jones and
               Florian Daiber and
               Zann Anderson and
               Kevin D. Seppi},
  title     = {{SIG} on Interactive Computing in Outdoor Recreation},
  booktitle = {Proceedings of the 2017 {CHI} Conference on Human Factors in Computing
               Systems, Denver, CO, USA, May 06-11, 2017, Extended Abstracts.},
  series    = {CHI EA '17},
  pages     = {1326--1329},
  numpages  = {4},
  year      = {2017},
  location  = {Denver, Colorado, USA},
  crossref  = {DBLP:conf/chi/2017a},
  isbn      = {978-1-4503-4656-6},
  acmid     = {3049289},
  url       = {http://doi.acm.org/10.1145/3027063.3049289},
  doi       = {10.1145/3027063.3049289},
  timestamp = {Tue, 02 May 2017 19:27:29 +0200},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {nature, outdoor recreation, sports technologies, ubiquitous computing},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/chi/JonesDAS17},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Interactive computing has impacted how people experience outdoor recreation. Nevertheless, the role of interactive computing in outdoor recreation can be complicated. Some people engage in outdoor recreation precisely to avoid distractions associated with pervasive interactive computing. Others use interactive computing to create, enhance or share outdoor recreation experiences. In this SIG, participants will discuss research questions and foundational theories that might guide future work related to interactive computing in outdoor recreation. The discussion will range from engineering issues to research methods. Attendees will have opportunities to stay connected after the SIG.}
}

@inproceedings{FastInference2016,
  author    = {Jeffrey Lund and
               Paul Felt and
               Kevin D. Seppi and
               Eric K. Ringger},
  title     = {Fast Inference for Interactive Models of Text},
  booktitle = {{COLING} 2016, 26th International Conference on Computational Linguistics,
               Proceedings of the Conference: Technical Papers, December 11-16, 2016,
               Osaka, Japan},
  pages     = {2997--3006},
  year      = {2016},
  crossref  = {DBLP:conf/coling/2016},
  url       = {http://aclweb.org/anthology/C/C16/C16-1282.pdf},
  timestamp = {Thu, 15 Dec 2016 16:57:46 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/coling/LundFSR16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract  = {Probabilistic models are a useful means for analyzing large text corpora. Integrating such models
with human interaction enables many new use cases. However, adding human interaction to
probabilistic models requires inference algorithms which are both fast and accurate. We explore
the use of Iterated Conditional Modes as a fast alternative to Gibbs sampling or variational EM.
We demonstrate superior performance both in run time and model quality on three different
models of text including a DP Mixture of Multinomials for web search result clustering, the
Interactive Topic Model, and MOMRESP, a multinomial crowdsourcing model.}
}

@inproceedings{Embeddings2016,
  author    = {Paul Felt and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Semantic Annotation Aggregation with Conditional Crowdsourcing Models
               and Word Embeddings},
  booktitle = {{COLING} 2016, 26th International Conference on Computational Linguistics,
               Proceedings of the Conference: Technical Papers, December 11-16, 2016,
               Osaka, Japan},
  pages     = {1787--1796},
  year      = {2016},
  crossref  = {DBLP:conf/coling/2016},
  url       = {http://aclweb.org/anthology/C/C16/C16-1168.pdf},
  timestamp = {Thu, 15 Dec 2016 16:57:46 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/coling/FeltRS16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract  = {In modern text annotation projects, crowdsourced annotations are often aggregated using item
response models or by majority vote. Recently, item response models enhanced with generative
data models have been shown to yield substantial benefits over those with conditional or
no data models. However, suitable generative data models do not exist for many tasks, such as
semantic labeling tasks. When no generative data model exists, we demonstrate that similar benefits
may be derived by conditionally modeling documents that have been previously embedded
in a semantic space using recent work in vector space models. We use this approach to show
state-of-the-art results on a variety of semantic annotation aggregation tasks.}
}

@inproceedings{MRS2017,
  author    = {Jeffrey Lund and
               Chace Ashcraft and
               Andrew W. McNabb and
               Kevin D. Seppi},
  title     = {Mrs: High Performance MapReduce for Iterative and Asynchronous Algorithms
               in Python},
  booktitle = {6th Workshop on Python for High-Performance and Scientific Computing,
               PyHPC@SC 2016, Salt Lake, UT, USA, November 14, 2016},
  series    = {PyHPC '16},
  location  = {Salt Lake City, Utah},
  pages     = {76--85},
  numpages  = {10},
  year      = {2016},
  crossref  = {DBLP:conf/sc/2016pyhpc},
  url       = {https://doi.org/10.1109/PyHPC.2016.014},
  doi       = {10.1109/PyHPC.2016.014},
  acmid     = {3019093},
  isbn      = {978-1-5090-5220-2},
  timestamp = {Tue, 23 May 2017 01:07:25 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sc/LundAMS16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  publisher = {IEEE Press},
  address   = {Piscataway, NJ, USA},
  keywords = {high-level parallel programming frameworks, iterative algorithms, mapreduce},
  abstract  = {Mrs is a lightweight Python-based MapReduce implementation designed to make MapReduce programs easy to write and quick to run, particularly useful for research and academia. A common set of algorithms that would benefit from Mrs are iterative algorithms, like those frequently found in machine learning; however, iterative algorithms typically perform poorly in the MapReduce framework, meaning potentially poor performance in Mrs as well. Therefore, we propose four modifications to the original Mrs with the intent to improve its ability to perform iterative algorithms. First, we used direct task-to-task communication for most iterations and only occasionally write to a distributed file system to preserve fault tolerance. Second, we combine the reduce and map tasks which span successive iterations to eliminate unnecessary communication and scheduling latency. Third, we propose a generator-callback programming model to allow for greater flexibility in the scheduling of tasks. Finally, some iterative algorithms are naturally expressed in terms of asynchronous message passing, so we propose a fully asynchronous variant of MapReduce. We then demonstrate Mrs' enhanced performance in the context of two iterative applications: particle swarm optimization (PSO), and expectation maximization (EM).}
}

@inproceedings{ExpressingRequirements2016,
  author    = {Daqing Yi and
               Thomas M. Howard and
               Michael A. Goodrich and
               Kevin D. Seppi},
  title     = {Expressing homotopic requirements for mobile robot navigation through
               natural language instructions},
  booktitle = {2016 {IEEE/RSJ} International Conference on Intelligent Robots and
               Systems, {IROS} 2016, Daejeon, South Korea, October 9-14, 2016},
  pages     = {1462--1468},
  year      = {2016},
  crossref  = {DBLP:conf/iros/2016},
  url       = {https://doi.org/10.1109/IROS.2016.7759238},
  doi       = {10.1109/IROS.2016.7759238},
  timestamp = {Mon, 22 May 2017 17:11:38 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iros/YiHGS16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Allowing a human to express topological requirements to a robot in language enables untrained users to guide robot movement without requiring the human to understand sophisticated robot algorithms. By using a homotopy class or classes to represent one or more topological requirements, we build a framework that helps a robot understand a human's intent. This paper reviews a homotopic decomposition method that is used to convert any path into a string, which allows homotopic path equivalence to be performed by comparing strings. We then integrate the Homotopic Distributed Correspondence Graph (HoDCG) to infer the homotopic constraint in the format of strings from a language instruction. Finally, we use a homotopic path-planning algorithm that finds the optimal paths for a given objective and homotopic constraint. Experiment results show how a language instruction is converted into a path driven by an implicit topological requirement.}
}

@inproceedings{ActiveWithTopics2016,
  author    = {Forough Poursabzi{-}Sangdeh and
               Jordan L. Boyd{-}Graber and
               Leah Findlater and
               Kevin D. Seppi},
  title     = {{ALTO:} Active Learning with Topic Overviews for Speeding Label Induction
               and Document Labeling},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
               1: Long Papers},
  year      = {2016},
  crossref  = {DBLP:conf/acl/2016-1},
  url       = {http://aclweb.org/anthology/P/P16/P16-1110.pdf},
  timestamp = {Mon, 15 Aug 2016 20:10:51 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/acl/Poursabzi-Sangdeh16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract  = {Effective text classification requires experts
to annotate data with labels; these training
data are time-consuming and expensive to
obtain. If you know what labels you want,
active learning can reduce the number of
labeled documents needed. However, establishing
the label set remains difficult. Annotators
often lack the global knowledge
needed to induce a label set. We introduce
ALTO: Active Learning with Topic
Overviews, an interactive system to help
humans annotate documents: topic models
provide a global overview of what labels
to create and active learning directs
them to the right documents to label. Our
forty-annotator user study shows that while
active learning alone is best in extremely
resource limited conditions, topic models
(even by themselves) lead to better label
sets, and ALTO’s combination is best overall.}
}

@inproceedings{HumanTopics2016,
  title={Human-Centered and Interactive: Expanding the Impact of Topic Models},
  author={Smith, Alison and Yeon Lee, Tak and Poursabzi-Sangdeh, Forough and Boyd-Graber, Jordan and Elmqvist, Niklas and Seppi, Kevin and Findlater, Leah},
  booktitle={Proc. HCML Workshop at CHI 2016},
  year={2016},
  url={http://www.doc.gold.ac.uk/~mas02mg/HCML2016/HCML2016_paper_18.pdf},
  abstract={Statistical topic modeling is a common tool for
summarizing the themes in a document corpus. Due to
the complexity of topic modeling algorithms, however,
their results are not accessible to non-expert users.
Recent work in interactive topic modeling looks to
incorporate the user into the inference loop, for
example, by allowing them to view a model then
update it by specifying important words and words that
should be ignored. However, the majority of interactive
topic modeling work has been performed without fully
understanding the needs of the end user and does not
adequately consider challenges that arise in interactive
machine learning. In this paper, we outline a subset of
interactive machine learning design challenges with
specific considerations for interactive topic modeling.
For each challenge, we propose solutions based on
prior work and our own preliminary findings and
identify open questions to guide future work.}
}

@inproceedings{Clay2O16,
  author    = {Michael D. Jones and
               Kevin D. Seppi and
               Dan R. Olsen},
  title     = {What you Sculpt is What you Get: Modeling Physical Interactive Devices
               with Clay and 3D Printed Widgets},
  booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing
               Systems, San Jose, CA, USA, May 7-12, 2016},
  series    = {CHI '16},
  location  = {Santa Clara, California, USA},
  pages     = {876--886},
  numpages  = {11},
  year      = {2016},
  crossref  = {DBLP:conf/chi/2016},
  url       = {http://doi.acm.org/10.1145/2858036.2858493},
  doi       = {10.1145/2858036.2858493},
  isbn      = {978-1-4503-3362-7},
  acmid     = {2858493},
  timestamp = {Sun, 08 May 2016 11:21:21 +0200},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {3D printing, physical computing, prototypes},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/chi/JonesSO16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract  = {We present a method for fabricating prototypes of interactive computing devices from clay sculptures without requiring the designer to be skilled in CAD software. The method creates a "what you sculpt is what you get" process that mimics the "what you see is what you get" processes used in interface design for 2D screens. Our approach uses clay for modeling the basic shape of the device around 3D printed representations, which we call "blanks", of physical interaction widgets such as buttons, sliders, knobs and other electronics. Each blank includes 4 fiducial markers uniquely arranged on a visible surface. After scanning the sculpture, these fiducial marks allow our software to identify widget types and locations in the scanned model. The software then converts the scan into a printable prototype by positioning mounting surfaces, openings for the controls and a splitting plane for assembly. Because the blanks fit in the sculpted shape, they will reliably fit in the interactive prototype. Creating an interactive prototype requires about 30 minutes of human effort for sculpting, and after scanning, involves a single button click to use the process.}
}


@inproceedings{HomotopyRRT2016,
  author    = {Daqing Yi and
               Michael A. Goodrich and
               Kevin D. Seppi},
  title     = {Homotopy-Aware RRT*: Toward Human-Robot Topological Path-Planning},
  booktitle = {The Eleventh {ACM/IEEE} International Conference on Human Robot Interation,
               {HRI} 2016, Christchurch, New Zealand, March 7-10, 2016},
  pages     = {279--286},
  numpages  = {8},
  series    = {HRI '16},
  location  = {Christchurch, New Zealand},
  year      = {2016},
  crossref  = {DBLP:conf/hri/2016},
  url       = {http://dl.acm.org/citation.cfm?id=2906831.2906880},
  doi       = {10.1109/HRI.2016.7451763},
  isbn      = {978-1-4673-8370-7},
  acmid     = {2906880},
  timestamp = {Fri, 26 May 2017 00:49:51 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/hri/YiGS16},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  publisher = {IEEE Press},
  address   = {Piscataway, NJ, USA},
  keywords  = {homotopy, human-robot teaming, interactive path-planning, topology},
  abstract  = {An important problem in human-robot interaction is for a human to be able to tell the robot go to a particular location with instructions on how to get there or what to avoid on the way. This paper provides a solution to problems where the human wants the robot not only to optimize some objective but also to honor “soft” or “hard” topological constraints, i.e. “go quickly from A to B while avoiding C”. The paper presents the HARRT* (homotopy-aware RRT*) algorithm, which is a computationally scalable algorithm that a robot can use to plan optimal paths subject to the information provided by the human. The paper provides a theoretic justification for the key property of the algorithm, proposes a heuristic for RRT*, and uses a set of simulation case studies of the resulting algorithm to make a case for why these properties are compatible with the requirements of human-robot interactive path-planning.}
}

@inproceedings{UrbanLearning2015,
  author    = {He Bai and
               Kevin Cook and
               Huili Yu and
               Kyle Ingersoll and
               Randy Beard and
               Kevin D. Seppi and
               Sharath Avadhanam},
  title     = {Improving cooperative tracking of an urban target with target motion
               model learning},
  booktitle = {54th {IEEE} Conference on Decision and Control, {CDC} 2015, Osaka,
               Japan, December 15-18, 2015},
  pages     = {2347--2352},
  year      = {2015},
  crossref  = {DBLP:conf/cdc/2015},
  url       = {https://doi.org/10.1109/CDC.2015.7402558},
  doi       = {10.1109/CDC.2015.7402558},
  timestamp = {Fri, 19 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cdc/BaiCYIBSA15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Tracking a ground urban target with multiple unmanned aerial vehicles (UAVs) is a challenging problem due to cluttered urban environments and coordination of nonholonomic UAV motion. Our previous work has demonstrated in simulation that machine learning can be used in such an environment to learn a model of target motion and thereby improve tracking performance. We extend this previous work by creating a more realistic simulation using road network and building height data extracted from downtown San Diego. We demonstrate effectiveness of target motion model learning in the new simulation environment. Additionally, we demonstrate performance improvement by extending the algorithm used to coordinate the UAVs for tracking the urban target.}
}

@inproceedings{ConfusedSLDA2015,
  author    = {Paul Felt and
               Eric K. Ringger and
               Jordan L. Boyd{-}Graber and
               Kevin D. Seppi},
  title     = {Making the Most of Crowdsourced Document Annotations: Confused Supervised
               {LDA}},
  booktitle = {Proceedings of the 19th Conference on Computational Natural Language
               Learning, CoNLL 2015, Beijing, China, July 30-31, 2015},
  pages     = {194--203},
  year      = {2015},
  crossref  = {DBLP:conf/conll/2015},
  url       = {http://aclweb.org/anthology/K/K15/K15-1020.pdf},
  timestamp = {Mon, 03 Aug 2015 14:36:31 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/conll/FeltRBS15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Corpus labeling projects frequently use
low-cost workers from microtask marketplaces;
however, these workers are often
inexperienced or have misaligned incentives.
Crowdsourcing models must be robust
to the resulting systematic and nonsystematic
inaccuracies. We introduce a
novel crowdsourcing model that adapts the
discrete supervised topic model sLDA to
handle multiple corrupt, usually conflicting
(hence “confused”) supervision signals.
Our model achieves significant gains
over previous work in the accuracy of deduced
ground truth.}
}

@inproceedings{MultiObjectivePlanning2015,
  author    = {Daqing Yi and
               Michael A. Goodrich and
               Kevin D. Seppi},
  title     = {MORRF*: Sampling-Based Multi-Objective Motion Planning},
  booktitle = {Proceedings of the Twenty-Fourth International Joint Conference on
               Artificial Intelligence, {IJCAI} 2015, Buenos Aires, Argentina, July
               25-31, 2015},
  series    = {IJCAI'15},
  location  = {Buenos Aires, Argentina},
  pages     = {1733--1739},
  numpages  = {7},
  year      = {2015},
  crossref  = {DBLP:conf/ijcai/2015},
  publisher = {AAAI Press},
  url       = {http://dl.acm.org/citation.cfm?id=2832415.2832490},
  isbn      = {978-1-57735-738-4},
  acmid     = {2832490},
  timestamp = {Wed, 20 Jul 2016 15:18:06 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ijcai/YiGS15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Many robotic tasks require solutions that maximize multiple performance objectives. For example, in path-planning, these objectives often include finding short paths that avoid risk and maximize the information obtained by the robot. Although there exist many algorithms for multi-objective optimization, few of these algorithms apply directly to robotic path-planning and fewer still are capable of finding the set of Pareto optimal solutions. We present the MORRF* (Multi-Objective Rapidly exploring Random Forest*) algorithm, which blends concepts from two different types of algorithms from the literature: Optimal rapidly exploring random tree (RRT*) for efficient path finding [Karaman and Frazzoli, 2010] and a decomposition-based approach to multi-objective optimization [Zhang and Li, 2007]. The random forest uses two types of tree structures: a set of reference trees and a set of subproblem trees. We present a theoretical analysis that demonstrates that the algorithm asymptotically produces the set of Pareto optimal solutions, and use simulations to demonstrate the effectiveness and efficiency of MORRF* in approximating the Pareto set.}
}

@inproceedings{PSOStability2015,
  author    = {Daqing Yi and
               Kevin Seppi and
               Michael Goodrich},
  title     = {Input-to-State Stability Analysis on Particle Swarm Optimization},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference,
               {GECCO} 2015, Madrid, Spain, July 11-15, 2015},
  series    = {GECCO '15},
  pages     = {81--88},
  numpages  = {8},
  location  = {Madrid, Spain},
  year      = {2015},
  crossref  = {DBLP:conf/gecco/2015},
  url       = {http://doi.acm.org/10.1145/2739480.2754782},
  doi       = {10.1145/2739480.2754782},
  isbn      = {978-1-4503-3472-3},
  acmid     = {2754782},
  timestamp = {Wed, 30 Dec 2015 09:05:01 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/YiSG15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {input-to-state stability, particle swarm optimization},
  abstract  = {This paper examines the dynamics of particle swarm optimization (PSO) by modeling PSO as a feedback cascade system and then applying input-to-state stability analysis. Using a feedback cascade system model we can include the effects of the global-best and personal-best values more directly in the model of the dynamics. Thus in contrast to previous study of PSO dynamics, the input-to-state stability property used here allows for the analysis of PSO both before and at stagnation. In addition, the use of input-to-state stability allows this analysis to preserve random terms which were heretofore simplified to constants. This analysis is important because it can inform the setting of PSO parameters and better characterize the nature of PSO as a dynamic system. This work also illuminates the way in which the personal-best and the global-best updates influence the bound on the particle's position and hence, how the algorithm exploits and explores the fitness landscape as a function of the personal best and global best.}
}

@inproceedings{SupervisedAnchors2015,
  author    = {Thang Nguyen and
               Jordan L. Boyd{-}Graber and
               Jeffrey Lund and
               Kevin D. Seppi and
               Eric K. Ringger},
  title     = {Is Your Anchor Going Up or Down? Fast and Accurate Supervised Topic
               Models},
  booktitle = {{NAACL} {HLT} 2015, The 2015 Conference of the North American Chapter
               of the Association for Computational Linguistics: Human Language Technologies,
               Denver, Colorado, USA, May 31 - June 5, 2015},
  pages     = {746--755},
  year      = {2015},
  crossref  = {DBLP:conf/naacl/2015},
  url       = {http://aclweb.org/anthology/N/N15/N15-1076.pdf},
  timestamp = {Sat, 11 Jul 2015 19:34:33 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/naacl/NguyenBLSR15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Topic models provide insights into document
collections, and their supervised extensions
also capture associated document-level metadata
such as sentiment. However, inferring
such models from data is often slow and cannot
scale to big data. We build upon the “anchor”
method for learning topic models to capture the
relationship between metadata and latent topics
by extending the vector-space representation
of word-cooccurrence to include metadataspecific
dimensions. These additional dimensions
reveal new anchor words that reflect specific
combinations of metadata and topic. We
show that these new latent representations predict
sentiment as accurately as supervised topic
models, and we find these representations more
quickly without sacrificing interpretability.}
}

@inproceedings{EarlyCrowdsourcing2015,
  author    = {Paul Felt and
               Kevin Black and
               Eric K. Ringger and
               Kevin D. Seppi and
               Robbie Haertel},
  title     = {Early Gains Matter: {A} Case for Preferring Generative over Discriminative
               Crowdsourcing Models},
  booktitle = {{NAACL} {HLT} 2015, The 2015 Conference of the North American Chapter
               of the Association for Computational Linguistics: Human Language Technologies,
               Denver, Colorado, USA, May 31 - June 5, 2015},
  pages     = {882--891},
  year      = {2015},
  crossref  = {DBLP:conf/naacl/2015},
  url       = {http://aclweb.org/anthology/N/N15/N15-1089.pdf},
  timestamp = {Sat, 11 Jul 2015 19:34:33 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/naacl/FeltBRSH15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {In modern practice, labeling a dataset often
involves aggregating annotator judgments
obtained from crowdsourcing. State-of-theart
aggregation is performed via inference on
probabilistic models, some of which are dataaware,
meaning that they leverage features of
the data (e.g., words in a document) in addition
to annotator judgments. Previous work
largely prefers discriminatively trained conditional
models. This paper demonstrates that
a data-aware crowdsourcing model incorporating
a generative multinomial data model
enjoys a strong competitive advantage over
its discriminative log-linear counterpart in the
typical crowdsourcing setting. That is, the
generative approach is better except when the
annotators are highly accurate in which case
simple majority vote is often sufficient. Additionally,
we present a novel mean-field variational
inference algorithm for the generative
model that significantly improves on the previously
reported state-of-the-art for that model.
We validate our conclusions on six text classification
datasets with both human-generated
and synthetic annotations.}
}

@inproceedings{EvaluationROI2015,
  author    = {Robbie Haertel and
               Eric K. Ringger and
               Kevin D. Seppi and
               Paul Felt},
  title     = {An Analytic and Empirical Evaluation of Return-on-Investment-Based
               Active Learning},
  booktitle = {Proceedings of The 9th Linguistic Annotation Workshop, LAW@NAACL-HLT
               2015, June 5, 2015, Denver, Colorado, {USA}},
  pages     = {11--20},
  year      = {2015},
  crossref  = {DBLP:conf/acllaw/2015},
  url       = {http://aclweb.org/anthology/W/W15/W15-1602.pdf},
  timestamp = {Tue, 20 Sep 2016 19:16:02 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/acllaw/HaertelRSF15},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Return-on-Investment (ROI) is a costconscious
approach to active learning (AL)
that considers both estimates of cost and
of benefit in active sample selection. We
investigate the theoretical conditions for
successful cost-conscious AL using ROI by
examining the conditions under which ROI
would optimize the area under the cost/benefit
curve. We then empirically measure the
degree to which optimality is jeopardized in
practice when the conditions are violated.
The reported experiments involve an English
part-of-speech annotation task. Our results
show that ROI can indeed successfully reduce
total annotation costs and should be considered
as a viable option for machine-assisted
annotation. On the basis of our experiments,
we make recommendations for benefit estimators
to be employed in ROI. In particular,
we find that the more linearly related a benefit
estimate is to the true benefit, the better the
estimate performs when paired in ROI with
an imperfect cost estimate. Lastly, we apply
our analysis to help explain the mixed results
of previous work on these questions.}
}

@inproceedings{Multinomial2014,
    author = {Paul Felt and Kevin Black and Eric Ringger and Kevin Seppi and Robbie Haertel},
    title = {On Multinomial vs. Log-linear Crowdsourcing Models with Mean-field Variational Inference},
    booktitle = {The Proceedings of the NIPS 2014 Workshop on Crowdsourcing and Machine Learning},
    year = {2014},
    location = {Montreal, Quebec}
}

@INPROCEEDINGS{PSOMomentum2014, 
author={C. K. Monson and K. D. Seppi}, 
booktitle={2014 IEEE Symposium on Swarm Intelligence}, 
title={Confident but weakly informed: Tackling PSO's momentum conundrum}, 
    location = {Orlando, Florida},
year={2014}, 
pages={1-8}, 
abstract={Particle Swarm Optimization uses noisy historical information to select potentially optimal function samples. Though information-theoretic principles suggest that less noise indicates greater certainty, PSO's momentum term is usually both the least informed and the most deterministic. This dichotomy suggests that while momentum has a profound impact on swarm diversity, it would benefit from a more principled approach. We demonstrate that momentum can be made both more effective and better behaved with informed feedback, and that it may even be completely eliminated with proper application of more straightforward and well-behaved diversity injection strategies.}, 
keywords={information theory;particle swarm optimisation;PSO momentum conundrum;diversity injection strategies;information-theoretic principles;informed feedback;noisy historical information;particle swarm optimization;swarm diversity;Noise;Optimization;Standards;Topology;Tuning;Uncertainty;Vectors}, 
doi={10.1109/SIS.2014.7011776}, 
url       = {https://dx.doi.org/10.1109/SIS.2014.7011776},
month={Dec},}

@inproceedings{InformedPath2014,
  author    = {Daqing Yi and
               Michael A. Goodrich and
               Kevin D. Seppi},
  title     = {Informative path planning with a human path constraint},
  booktitle = {2014 {IEEE} International Conference on Systems, Man, and Cybernetics,
               {SMC} 2014, San Diego, CA, USA, October 5-8, 2014},
  pages     = {1752--1758},
  year      = {2014},
  crossref  = {DBLP:conf/smc/2014},
  url       = {https://doi.org/10.1109/SMC.2014.6974170},
  doi       = {10.1109/SMC.2014.6974170},
  timestamp = {Wed, 17 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/smc/YiGS14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {One way for a human and a robot to collaborate on a search task is for the human to specify constraints on the robot's path and then allow the robot to find an optimal path subject to these constraints. This paper presents an anytime solution to the robot's path-planning problem when the human specifies a path constraint and an acceptable amount of deviation from this path. The robot's objective is to maximize information gathered during the search subject to this constraint. We first discretize the path constraint and then convert the resulting problem into a multi-partite graph. Information maximization becomes a submodular orienteering problem on this topology structure. Backtracking is used to generate an efficient heuristic for solving this problem, and an expanding tree is used to facilitate an anytime algorithm.}
}

@inproceedings{UnderInformedPSO2014,
  author    = {Christopher K. Monson and
               Kevin D. Seppi},
  title     = {Under-informed momentum in {PSO}},
  booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} '14, Vancouver,
               BC, Canada, July 12-16, 2014, Companion Material Proceedings},
  series    = {GECCO Comp '14},
  location  = {Vancouver, BC, Canada},
  pages     = {13--14},
  numpages  = {2},
  year      = {2014},
  crossref  = {DBLP:conf/gecco/2014c},
  url       = {http://doi.acm.org/10.1145/2598394.2598490},
  doi       = {10.1145/2598394.2598490},
  isbn      = {978-1-4503-2881-4},
  acmid     = {2598490},
  timestamp = {Sat, 12 Jul 2014 15:03:19 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/MonsonS14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {particle swarm optimization},
  abstract  = {Particle Swarm Optimization is fundamentally a stochastic algorithm, where each particle takes into account noisy information from its own history as well as that of its neighborhood. Though basic information-theoretic principles would suggest that less noise indicates greater certainty, the momentum term is simultaneously the least directly-informed and the most deterministically applied. This dichotomy suggests that the typically confident treatment of momentum is misplaced, and that swarm performance can benefit from better-motivated processes that obviate momentum entirely.}
}

@INPROCEEDINGS{SerialPSO2014, 
author={A. McNabb and K. Seppi}, 
booktitle={2014 IEEE Congress on Evolutionary Computation (CEC)}, 
title={Serial PSO results are irrelevant in a multi-core parallel world}, 
year={2014}, 
pages={3143-3150}, 
abstract={From multi-core processors to parallel GPUs to computing clusters, computing resources are increasingly parallel. These parallel resources are being used to address increasingly challenging applications. This presents an opportunity to design optimization algorithms that use parallel processors efficiently. In spite of the intuitively parallel nature of Particle Swarm Optimization (PSO), most PSO variants are not evaluated from a parallel perspective and introduce extra communication and bottlenecks that are inefficient in a parallel environment. We argue that the standard practice of evaluating a PSO variant by reporting function values with respect to the number of function evaluations is inadequate for evaluating PSO in a parallel environment. Evaluating the parallel performance of a PSO variant instead requires reporting function values with respect to the number of iterations to show how the algorithm scales with the number of processors, along with an implementation-independent description of task interactions and communication. Furthermore, it is important to acknowledge the dependence of performance on specific properties of the objective function and computational resources. We discuss parallel evaluation of PSO, and we review approaches for increasing concurrency and for reducing communication which should be considered when discussing the scalability of a PSO variant. This discussion is essential both for designers who are defending the performance of an algorithm and for practitioners who are determining how to apply PSO for a given objective function and parallel environment.}, 
keywords={graphics processing units;iterative methods;mathematics computing;multiprocessing systems;particle swarm optimisation;PSO variant;computational resources;computing clusters;computing resources;function evaluations;function values;implementation-independent description;multicore parallel world;multicore processors;objective function;optimization algorithms;parallel GPU;parallel processors;parallel resources;particle swarm optimization;task communication;task interactions;Benchmark testing;Concurrent computing;Equations;Linear programming;Particle swarm optimization;Program processors;Topology}, 
doi={10.1109/CEC.2014.6900226}, 
  url       = {https://doi.org/10.1109/CEC.2014.6900226},
ISSN={1089-778X}, 
month={July},}

@inproceedings{Lemmatization2014,
  author    = {Kevin Black and
               Eric K. Ringger and
               Paul Felt and
               Kevin D. Seppi and
               Kristian Heal and
               Deryle Lonsdale},
  title     = {Evaluating Lemmatization Models for Machine-Assisted Corpus-Dictionary
               Linkage},
  booktitle = {Proceedings of the Ninth International Conference on Language Resources
               and Evaluation, {LREC} 2014, Reykjavik, Iceland, May 26-31, 2014.},
  pages     = {3798--3805},
  year      = {2014},
  month = {may},
  crossref  = {DBLP:conf/lrec/2014},
  url       = {http://www.lrec-conf.org/proceedings/lrec2014/summaries/1203.html},
  timestamp = {Mon, 29 Aug 2016 18:40:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/BlackRFSHL14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  address = {Reykjavik, Iceland},
  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Hrafn Loftsson and Bente Maegaard and Joseph Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-8-4},
  language = {english},
  abstract = {The task of corpus-dictionary linkage (CDL) is to annotate each word in a corpus with a link to an appropriate dictionary entry that documents the sense and usage of the word. Corpus-dictionary linked resources include concordances, dictionaries with word usage examples, and corpora annotated with lemmas or word-senses. Such CDL resources are essential in learning a language and in linguistic research, translation, and philology. Lemmatization is a common approximation to automating corpus-dictionary linkage, where lemmas are treated as dictionary entry headwords. We intend to use data-driven lemmatization models to provide machine assistance to human annotators in the form of pre-annotations, and thereby reduce the costs of CDL annotation. In this work we adapt the discriminative string transducer DirecTL+ to perform lemmatization for classical Syriac, a low-resource language. We compare the accuracy of DirecTL+ with the Morfette discriminative lemmatizer. DirecTL+ achieves 96.92\% overall accuracy but only by a margin of 0.86\% over Morfette at the cost of a longer time to train the model. Error analysis on the models provides guidance on how to apply these models in a machine assistance setting for corpus-dictionary linkage.}
 }

@inproceedings{Momresp2014,
  author    = {Paul Felt and
               Robbie Haertel and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Momresp: {A} Bayesian Model for Multi-Annotator Document Labeling},
  booktitle = {Proceedings of the Ninth International Conference on Language Resources
               and Evaluation, {LREC} 2014, Reykjavik, Iceland, May 26-31, 2014.},
  pages     = {3704--3711},
  year      = {2014},
  crossref  = {DBLP:conf/lrec/2014},
  url       = {http://www.lrec-conf.org/proceedings/lrec2014/summaries/1153.html},
  timestamp = {Mon, 29 Aug 2016 18:40:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/FeltHRS14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  address = {Reykjavik, Iceland},
  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Hrafn Loftsson and Bente Maegaard and Joseph Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-8-4},
  language = {english},
  abstract = {Data annotation in modern practice often involves multiple, imperfect human annotators. Multiple annotations can be used to infer estimates of the ground-truth labels and to estimate individual annotator error characteristics (or reliability). We introduce MomResp, a model that incorporates information from both natural data clusters as well as annotations from multiple annotators to infer ground-truth labels and annotator reliability for the document classification task. We implement this model and show dramatic improvements over majority vote in situations where both annotations are scarce and annotation quality is low as well as in situations where annotators disagree consistently. Because MomResp predictions are subject to label switching, we introduce a solution that finds nearly optimal predicted class reassignments in a variety of settings using only information available to the model at inference time. Although MomResp does not perform well in annotation-rich situations, we show evidence suggesting how this shortcoming may be overcome in future work.}
}

@inproceedings{TransferAnnotation2014,
  author    = {Paul Felt and
               Eric K. Ringger and
               Kevin D. Seppi and
               Kristian Heal},
  title     = {Using Transfer Learning to Assist Exploratory Corpus Annotation},
  booktitle = {Proceedings of the Ninth International Conference on Language Resources
               and Evaluation, {LREC} 2014, Reykjavik, Iceland, May 26-31, 2014.},
  pages     = {140--145},
  year      = {2014},
  crossref  = {DBLP:conf/lrec/2014},
  url       = {http://www.lrec-conf.org/proceedings/lrec2014/summaries/147.html},
  timestamp = {Mon, 29 Aug 2016 18:40:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/FeltRSH14},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  address = {Reykjavik, Iceland},
  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Hrafn Loftsson and Bente Maegaard and Joseph Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-8-4},
  language = {english},
  abstract = {We describe an under-studied problem in language resource management: that of providing automatic assistance to annotators working in exploratory settings. When no satisfactory tagset already exists, such as in under-resourced or undocumented languages, it must be developed iteratively while annotating data. This process naturally gives rise to a sequence of datasets, each annotated differently. We argue that this problem is best regarded as a transfer learning problem with multiple source tasks. Using part-of-speech tagging data with simulated exploratory tagsets, we demonstrate that even simple transfer learning techniques can significantly improve the quality of pre-annotations in an exploratory annotation.}
}

@INPROCEEDINGS{Tracking2013, 
author={K. Cook and E. Bryan and H. Yu and H. Bai and K. Seppi and R. Beard}, 
booktitle={2013 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
title={Intelligent cooperative control for urban tracking with Unmanned Air Vehicles}, 
year={2013}, 
pages={1-7}, 
abstract={We introduce an intelligent cooperative control system for ground target tracking in a cluttered urban environment with a team of Unmanned Air Vehicles (UAVs). We extend the work of Yu et. al. [1] to add a machine learning component that uses observations of target position to learn a model of target motion. Our learner is the Sequence Memoizer [2], a Bayesian model for discrete sequence data, which we use to predict future target location identifiers, given a context of previous location identifiers. Simulated cooperative control of a team of 3 UAVs in a 100-block city filled with various sizes of buildings verifies that learning a model of target motion can improve target tracking performance.}, 
keywords={Bayes methods;aerospace computing;autonomous aerial vehicles;clutter;control engineering computing;cooperative systems;intelligent control;learning (artificial intelligence);motion control;multi-robot systems;position control;target tracking;Bayesian model;UAV;block city;building;cluttered urban environment;discrete sequence data;ground target tracking;intelligent cooperative control system;machine learning component;sequence memoizer;simulated cooperative control;target location identifier;target motion;target position;target tracking performance;unmanned air vehicle;urban tracking;Artificial intelligence;Buildings;Cities and towns;Control systems;Kinematics;Target tracking;Vehicles}, 
doi={10.1109/ICUAS.2013.6564667}, 
  url       = {https://doi.org/10.1109/ICUAS.2013.6564667},
month={May},}

@inproceedings{WikipediaTopics2013,
  author    = {Joshua A. Hansen and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Probabilistic Explicit Topic Modeling Using Wikipedia},
  booktitle = {Language Processing and Knowledge in the Web - 25th International
               Conference, {GSCL} 2013, Darmstadt, Germany, September 25-27, 2013.
               Proceedings},
  pages     = {69--82},
  year      = {2013},
  crossref  = {DBLP:conf/gldv/2013},
  url       = {https://doi.org/10.1007/978-3-642-40722-2_7},
  doi       = {10.1007/978-3-642-40722-2_7},
  timestamp = {Fri, 26 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gldv/HansenRS13},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Despite popular use of Latent Dirichlet Allocation (LDA) for automatic discovery of latent topics in document corpora, such topics lack connections with relevant knowledge sources such as Wikipedia, and they can be difficult to interpret due to the lack of meaningful topic labels. Furthermore, the topic analysis suffers from a lack of identifiability between topics across independently analyzed corpora but also across distinct runs of the algorithm on the same corpus. This paper introduces two methods for probabilistic explicit topic modeling that address these issues: Latent Dirichlet Allocation with Static Topic-Word Distributions (LDA-STWD), and Explicit Dirichlet Allocation (EDA). Both of these methods estimate topic-word distributions a priori from Wikipedia articles, with each article corresponding to one topic and the article title serving as a topic label. LDA-STWD and EDA overcome the nonidentifiability, isolation, and unintepretability of LDA output. We assess their effectiveness by means of crowd-sourced user studies on two tasks: topic label generation and document label generation. We find that LDA-STWD improves substantially upon the performance of the state-of-the-art on the document labeling task, and that both methods otherwise perform on par with a state-of-the-art post hoc method.}
}

@inproceedings{OCRTopics2013,
  author    = {Daniel David Walker and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Evaluating supervised topic models in the presence of {OCR} errors},
  booktitle = {Document Recognition and Retrieval XX, part of the IS{\&}T-SPIE
               Electronic Imaging Symposium, Burlingame, California, USA, February
               5-7, 2013, Proceedings},
  pages     = {865812},
  year      = {2013},
  crossref  = {DBLP:conf/drr/2013},
  url       = {https://doi.org/10.1117/12.2008345},
  doi       = {10.1117/12.2008345},
  timestamp = {Wed, 24 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/drr/WalkerRS13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Apiary2012,
  author    = {Andrew W. McNabb and
               Kevin D. Seppi},
  title     = {The Apiary Topology: Emergent Behavior in Communities of Particle
               Swarms},
  booktitle = {Parallel Problem Solving from Nature - {PPSN} {XII} - 12th International
               Conference, Taormina, Italy, September 1-5, 2012, Proceedings, Part
               {II}},
 series = {PPSN'12},
 location = {Taormina, Italy},
  pages     = {164--173},
 numpages = {10},
  year      = {2012},
  crossref  = {DBLP:conf/ppsn/2012-2},
  url       = {https://doi.org/10.1007/978-3-642-32964-7_17},
  doi       = {10.1007/978-3-642-32964-7_17},
 isbn = {978-3-642-32963-0},
 acmid = {2402729},
  timestamp = {Wed, 17 May 2017 14:24:30 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ppsn/McNabbS12},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {multiple swarms, parallel PSO, parallel computation, particle swarm optimization, subswarms, swarm topology},
 abstract = {In the natural world there are many swarms in any geographical region. In contrast, Particle Swarm Optimization (PSO) is usually used with a single swarm of particles. We define a simple new topology called Apiary and show that parallel communities of swarms give rise to emergent behavior that is fundamentally different from the behavior of a single swarm of identical total size. Furthermore, we show that subswarms are essential for scaling parallel PSO to more processors with computationally inexpensive objective functions. Surprisingly, subswarms are also beneficial for scaling PSO to high dimensional problems, even in single processor environments.}
}

@inproceedings{MRS2012,
  author    = {Andrew W. McNabb and
               Jeffrey Lund and
               Kevin D. Seppi},
  title     = {Mrs: MapReduce for Scientific Computing in Python},
  booktitle = {2012 {SC} Companion: High Performance Computing, Networking Storage
               and Analysis, Salt Lake City, UT, USA, November 10-16, 2012},
 series = {SCC '12},
  pages     = {600--608},
 numpages = {9},
  year      = {2012},
  crossref  = {DBLP:conf/sc/2012c},
 isbn = {978-0-7695-4956-9},
  url       = {https://doi.org/10.1109/SC.Companion.2012.84},
  doi       = {10.1109/SC.Companion.2012.84},
 acmid = {2477014},
  timestamp = {Tue, 23 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/sc/McNabbLS12},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {MapReduce, Python, scientific computing, iterative algorithms, Particle Swarm Optimization},
 abstract = {The MapReduce parallel programming model is designed for large-scale data processing, but its benefits, such as fault tolerance and automatic message routing, are also helpful for computationally-intensive algorithms. However, popular MapReduce frameworks such as Hadoop are slow for many scientific applications and are inconvenient on supercomputers and clusters which are common in research institutions. Mrs is a Python-based MapReduce framework that is well suited for scientific computing. We present comparisons of programs and run scripts to argue that Mrs is more convenient than Hadoop, the most popular MapReduce implementation. We also demonstrate that Mrs outperforms Hadoop for several types of problems that are relevant to scientific computing. In particular, Mrs demonstrates per-iteration overhead of about 0.3 seconds for Particle Swarm Optimization, while Hadoop takes at least 30 seconds for each MapReduce operation, a difference of two orders of magnitude.}
}

@inproceedings{SyriacAnnotation2012,
  author    = {Paul Felt and
               Eric K. Ringger and
               Kevin D. Seppi and
               Kristian Heal and
               Robbie Haertel and
               Deryle Lonsdale},
  title     = {First Results in a Study Evaluating Pre-annotation and Correction
               Propagation for Machine-Assisted Syriac Morphological Analysis},
  booktitle = {Proceedings of the Eighth International Conference on Language Resources
               and Evaluation, {LREC} 2012, Istanbul, Turkey, May 23-25, 2012},
  pages     = {878--885},
  year      = {2012},
  crossref  = {DBLP:conf/lrec/2012},
  url       = {http://www.lrec-conf.org/proceedings/lrec2012/summaries/511.html},
  timestamp = {Mon, 29 Aug 2016 18:40:10 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/FeltRSHHL12},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  month = {may},
  date = {23-25},
  address = {Istanbul, Turkey},
  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Uğur Doğan and Bente Maegaard and Joseph Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-7-7},
  language = {english},
  abstract = {Manual annotation of large textual corpora can be cost-prohibitive, especially for rare and under-resourced languages. One potential solution is pre-annotation: asking human annotators to correct sentences that have already been annotated, usually by a machine. Another potential solution is correction propagation: using annotator corrections to bad pre-annotations to dynamically improve to the remaining pre-annotations within the current sentence. The research presented in this paper employs a controlled user study to discover under what conditions these two machine-assisted annotation techniques are effective in increasing annotator speed and accuracy and thereby reducing the cost for the task of morphologically annotating texts written in classical Syriac. A preliminary analysis of the data indicates that pre-annotations improve annotator accuracy when they are at least 60\% accurate, and annotator speed when they are at least 80\% accurate. This research constitutes the first systematic evaluation of pre-annotation and correction propagation together in a controlled user study.}
 }

@inproceedings{NonparametricTime2012,
  author    = {Daniel David Walker and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Topics Over Nonparametric Time: {A} Supervised Topic Model Using Bayesian
               Nonparametric Density Estimation},
  booktitle = {Proceedings of the Ninth {UAI} Bayesian Modeling Applications Workshop,
               Catalina Island, United States, August 18, 2012},
 series = {BMAW'12},
 location = {Catalina Island, United States},
  pages     = {74--83},
 numpages = {10},
  year      = {2012},
  crossref  = {DBLP:conf/uai/2012bma},
  url       = {http://ceur-ws.org/Vol-962/paper09.pdf},
 acmid = {3023474},
  timestamp = {Mon, 30 May 2016 16:43:12 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/uai/WalkerRS12},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {CEUR-WS.org},
 address = {Aachen, Germany, Germany},
 abstract = {We propose a new supervised topic model
that uses a nonparametric density estimator
to model the distribution of real-valued
metadata given a topic. The model is similar
to Topics Over Time, but replaces the
beta distributions used in that model with a
Dirichlet process mixture of normals. The
use of a nonparametric density estimator
allows for the fitting of a greater class of
metadata densities. We compare our model
with existing supervised topic models in
terms of prediction and show that it is capable
of discovering complex metadata distributions
in both synthetic and real data}
}
% url = {http://dl.acm.org/citation.cfm?id=3023465.3023474},

@inproceedings{BayesianCombination2011,
  author    = {Kristine Monteith and
               James L. Carroll and
               Kevin D. Seppi and
               Tony R. Martinez},
  title     = {Turning Bayesian model averaging into Bayesian model combination},
  booktitle = {The 2011 International Joint Conference on Neural Networks, {IJCNN}
               2011, San Jose, California, USA, July 31 - August 5, 2011},
  pages     = {2657--2663},
  year      = {2011},
  crossref  = {DBLP:conf/ijcnn/2011},
  url       = {https://doi.org/10.1109/IJCNN.2011.6033566},
  doi       = {10.1109/IJCNN.2011.6033566},
  timestamp = {Fri, 26 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ijcnn/MonteithCSM11},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {Bayesian methods are theoretically optimal in
many situations. Bayesian model averaging is generally considered
the standard model for creating ensembles of learners
using Bayesian methods, but this technique is often outperformed
by more ad hoc methods in empirical studies. The
reason for this failure has important theoretical implications
for our understanding of why ensembles work. It has been
proposed that Bayesian model averaging struggles in practice
because it accounts for uncertainty about which model is
correct but still operates under the assumption that only one
of them is. In order to more effectively access the benefits
inherent in ensembles, Bayesian strategies should therefore be
directed more towards model combination rather than the
model selection implicit in Bayesian model averaging. This work
provides empirical verification for this hypothesis using several
different Bayesian model combination approaches tested on
a wide variety of classification problems. We show that even
the most simplistic of Bayesian model combination strategies
outperforms the traditional ad hoc techniques of bagging and
boosting, as well as outperforming BMA over a wide variety of
cases. This suggests that the power of ensembles does not come
from their ability to account for model uncertainty, but instead
comes from the changes in representational and preferential
bias inherent in the process of combining several different
models.}
}

@inproceedings{VMPacking2011,
  author    = {David Wilcox and
               Andrew W. McNabb and
               Kevin D. Seppi},
  title     = {Solving virtual machine packing with a Reordering Grouping Genetic
               Algorithm},
  booktitle = {Proceedings of the {IEEE} Congress on Evolutionary Computation, {CEC}
               2011, New Orleans, LA, USA, 5-8 June, 2011},
  pages     = {362--369},
  year      = {2011},
  crossref  = {DBLP:conf/cec/2011},
  url       = {https://doi.org/10.1109/CEC.2011.5949641},
  doi       = {10.1109/CEC.2011.5949641},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/WilcoxMS11},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {We formally define multi-capacity bin packing, a generalization of conventional bin packing, and develop an algorithm called Reordering Grouping Genetic Algorithm (RGGA) to assign VMs to servers. We first test RGGA on conventional bin packing problems and show that it yields excellent results but much more efficiently. We then generate a multi-constraint test set, and demonstrate the effectiveness of RGGA in this context. Lastly, we show the applicability of RGGA in its desired context by using it to develop an assignment of real virtual machines to servers.}
}

@inproceedings{SyriacModelTraining2011,
    author = {Eric Ringger and Kevin Seppi and Kristian Heal and Deryle Lonsdale and Paul Felt and Robbie Haertel and Peter McClanahan},
    title = {Computational Models of Syriac and How to Train Them},
    booktitle = {The Proceedings of the North American Syriac Symposium},
    year = {2011},
}

@inproceedings{TopicBrowser2010,
  title={The Topic Browser An Interactive Tool for Browsing Topic Models},
  author={Gardner, Matthew J and Lutes, Joshua and Lund, Jeff and Hansen, Josh and Walker, Dan and Ringger, Eric and Seppi, Kevin},
  booktitle={NIPS Workshop on Challenges of Data Visualization},
  volume={2},
  year={2010}
}

@inproceedings{VMAssignment2010,
  title={Probabilistic Virtual Machine Assignment},
  author={Gardner, Matthew J and Lutes, Joshua and Lund, Jeff and Hansen, Josh and Walker, Dan and Ringger, Eric and Seppi, Kevin},
  booktitle={The Proceeding of the First International Conference on Cloud Computing, GRIDs, and Virtualization},
  location={Lisbon, Portugal},
  year={2010}
}

@inproceedings{Speculative2010,
  author    = {Matthew Gardner and
               Andrew W. McNabb and
               Kevin D. Seppi},
  title     = {Speculative Evaluation in Particle Swarm Optimization},
  booktitle = {Parallel Problem Solving from Nature - {PPSN} XI, 11th International
               Conference, Krak{\'{o}}w, Poland, September 11-15, 2010. Proceedings,
               Part {II}},
 series = {PPSN'10},
 location = {Krak\&\#243;w, Poland},
  pages     = {61--70},
 numpages = {10},
  year      = {2010},
  crossref  = {DBLP:conf/ppsn/2010-2},
  url       = {https://doi.org/10.1007/978-3-642-15871-1_7},
  doi       = {10.1007/978-3-642-15871-1_7},
 isbn = {3-642-15870-6, 978-3-642-15870-4},
  timestamp = {Wed, 17 May 2017 14:24:29 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ppsn/GardnerMS10},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 acmid = {1887263},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 abstract = {Particle swarm optimization (PSO) has previously been parallelized only by adding more particles to the swarm or by parallelizing the evaluation of the objective function. However, some functions are more efficiently optimized with more iterations and fewer particles. Accordingly, we take inspiration from speculative execution performed in modern processors and propose speculative evaluation in PSO (SEPSO). Future positions of the particles are speculated and evaluated in parallel with current positions, performing two iterations of PSO at once.
We also propose another way of making use of these speculative particles, keeping the best position found instead of the position that PSO actually would have taken. We show that for a number of functions, speculative evaluation gives dramatic improvements over adding additional particles to the swarm.}
}
% url = {http://dl.acm.org/citation.cfm?id=1887255.1887263},

@inproceedings{ParallelAL2010,
 title = {Parallel Active Learning: Eliminating Wait Time with Minimal Staleness},
  author={Haertel, Robbie and Felt, Paul and Ringger, Eric and Seppi, Kevin},
  booktitle={Proceedings of the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing},
 series = {ALNLP '10},
 location = {Los Angeles, California},
  pages={33--41},
 numpages = {9},
  year={2010},
  organization={Association for Computational Linguistics},
 url = {http://dl.acm.org/citation.cfm?id=1860625.1860630},
 acmid = {1860630},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
  abstract = {A practical concern for Active Learning (AL)
is the amount of time human experts must wait
for the next instance to label. We propose a
method for eliminating this wait time independent
of specific learning and scoring algorithms
by making scores always available
for all instances, using old (stale) scores when
necessary. The time during which the expert
is annotating is used to train models and
score instances–in parallel–to maximize the
recency of the scores. Our method can be seen
as a parameterless, dynamic batch AL algorithm.
We analyze the amount of staleness
introduced by various AL schemes and then
examine the effect of the staleness on performance
on a part-of-speech tagging task on the
Wall Street Journal. Empirically, the parallel
AL algorithm effectively has a batch size of
one and a large candidate set size but eliminates
the time an annotator would have to wait
for a similarly parameterized batch scheme to
select instances. The exact performance of our
method on other tasks will depend on the relative
ratios of time spent annotating, training,
and scoring, but in general we expect our parameterless
method to perform favorably compared
to batch when accounting for wait time.}
}

@inproceedings{Dictionaries2010,
  author    = {Marc Carmen and
               Paul Felt and
               Robbie Haertel and
               Deryle Lonsdale and
               Peter McClanahan and
               Owen Merkling and
               Eric K. Ringger and
               Kevin D. Seppi},
  title     = {Tag Dictionaries Accelerate Manual Annotation},
  booktitle = {Proceedings of the International Conference on Language Resources
               and Evaluation, {LREC} 2010, 17-23 May 2010, Valletta, Malta},
  year      = {2010},
  crossref  = {DBLP:conf/lrec/2010},
  url       = {http://www.lrec-conf.org/proceedings/lrec2010/summaries/451.html},
  timestamp = {Wed, 02 Jun 2010 19:27:18 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/CarmenFHLMMRS10},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{CCASH2010,
  author    = {Paul Felt and
               Owen Merkling and
               Marc Carmen and
               Eric K. Ringger and
               Warren Lemmon and
               Kevin D. Seppi and
               Robbie Haertel},
  title     = {{CCASH:} {A} Web Application Framework for Efficient, Distributed
               Language Resource Development},
  booktitle = {Proceedings of the International Conference on Language Resources
               and Evaluation, {LREC} 2010, 17-23 May 2010, Valletta, Malta},
  year      = {2010},
  crossref  = {DBLP:conf/lrec/2010},
  url       = {http://www.lrec-conf.org/proceedings/lrec2010/summaries/360.html},
  timestamp = {Wed, 02 Jun 2010 19:27:18 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/FeltMCRLSH10},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{MorphologicalAnalyzer2010,
  author    = {Peter McClanahan and
               George Busby and
               Robbie Haertel and
               Kristian Heal and
               Deryle Lonsdale and
               Kevin D. Seppi and
               Eric K. Ringger},
  title     = {A Probabilistic Morphological Analyzer for Syriac},
  booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2010, 9-11 October 2010, {MIT} Stata
               Center, Massachusetts, USA, {A} meeting of SIGDAT, a Special Interest
               Group of the {ACL}},
 series = {EMNLP '10},
 location = {Cambridge, Massachusetts},
  pages     = {810--820},
 numpages = {11},
  year      = {2010},
  crossref  = {DBLP:conf/emnlp/2010},
  url       = {http://www.aclweb.org/anthology/D10-1079},
  timestamp = {Tue, 18 Jan 2011 09:34:37 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/emnlp/McClanahanBHHLSR10},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 acmid = {1870737},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
 abstract = {We define a probabilistic morphological analyzer
using a data-driven approach for Syriac in
order to facilitate the creation of an annotated
corpus. Syriac is an under-resourced Semitic
language for which there are no available language
tools such as morphological analyzers.
We introduce novel probabilistic models for
segmentation, dictionary linkage, and morphological
tagging and connect them in a pipeline
to create a probabilistic morphological analyzer
requiring only labeled data. We explore the performance
of models with varying amounts of
training data and find that with about 34,500
labeled tokens, we can outperform a reasonable
baseline trained on over 99,000 tokens and
achieve an accuracy of just over 80\%. When
trained on all available training data, our joint
model achieves 86.47\% accuracy, a 29.7\% reduction
in error rate over the baseline.}
}
% url = {http://dl.acm.org/citation.cfm?id=1870658.1870737},

@inproceedings{NamesNoisyOCR2010,
  author    = {Thomas L. Packer and
               Joshua F. Lutes and
               Aaron P. Stewart and
               David W. Embley and
               Eric K. Ringger and
               Kevin D. Seppi and
               Lee S. Jensen},
  title     = {Extracting person names from diverse and noisy {OCR} text},
  booktitle = {Proceedings of the Fourth Workshop on Analytics for Noisy Unstructured
               Text Data, {AND} 2010, Toronto, Ontario, Canada, October 26th, 2010
               (in conjunction with {CIKM} 2010)},
 series = {AND '10},
 location = {Toronto, ON, Canada},
  pages     = {19--26},
 numpages = {8},
  year      = {2010},
  crossref  = {DBLP:conf/and/2010},
  url       = {http://doi.acm.org/10.1145/1871840.1871845},
  doi       = {10.1145/1871840.1871845},
 isbn = {978-1-4503-0376-7},
 acmid = {1871845},
  timestamp = {Thu, 16 Dec 2010 13:35:06 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/and/PackerLSERSJ10},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CRF, MEMM, NER, information extraction, named entity recognition, noisy OCR, scanned document images},
 abstract = {Named entity recognition applied to scanned and OCRed historical documents can contribute to the discoverability of historical information. However, entity recognition from some historical corpora is much more difficult than from natively digital text because of the marked presence of word errors and absence of page layout information. How difficult can it be and what level of quality can be expected? We apply three typical extraction algorithms to the task of extracting person names from multiple types of noisy OCR documents found in the collection of a major genealogy content provider and compare their performance using a number of quality metrics. We also show an improvement in extraction quality using a majority-vote ensemble of the three extractors. We evaluate the extraction quality with respect to two references: what a human can manually extract from OCR output and from the original document images. We illustrate the challenges and opportunities at hand for extracting names from OCRed data and identify directions for further improvement.}
}

@inproceedings{SuperResolution2009,
  author    = {Neil Toronto and
               Bryan S. Morse and
               Kevin D. Seppi and
               Dan Ventura},
  title     = {Super-resolution via recapture and Bayesian effect modeling},
  booktitle = {2009 {IEEE} Computer Society Conference on Computer Vision and Pattern
               Recognition ({CVPR} 2009), 20-25 June 2009, Miami, Florida, {USA}},
  pages     = {2388--2395},
  year      = {2009},
  crossref  = {DBLP:conf/cvpr/2009},
  url       = {https://doi.org/10.1109/CVPRW.2009.5206691},
  doi       = {10.1109/CVPRW.2009.5206691},
  timestamp = {Thu, 25 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cvpr/TorontoMSV09},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract = {This paper presents Bayesian edge inference (BEI), a single frame super resolution method explicitly grounded in Bayesian inference that addresses issues common to existing methods. Though the best give excellent results at modest magnification factors, they suffer from gradient stepping and boundary coherence problems by factors of 4x. Central to BEI is a causal framework that allows image capture and recapture to be modeled differently, a principled way of undoing downsampling blur, and a technique for incorporating Markov random field potentials arbitrarily into Bayesian networks. Besides addressing gradient and boundary issues, BEI is shown to be competitive with existing methods on published correctness measures. The model and framework are shown to generalize to other reconstruction tasks by demonstrating BEI's effectiveness at CCD demosaicing and inpainting with only trivial changes.}
}

@inproceedings{PSOTopologies2009,
 author = {McNabb, Andrew and Gardner, Matthew and Seppi, Kevin},
 title = {An Exploration of Topologies and Communication in Large Particle Swarms},
 booktitle = {Proceedings of the Eleventh Conference on Congress on Evolutionary Computation},
 series = {CEC'09},
 year = {2009},
 isbn = {978-1-4244-2958-5},
 location = {Trondheim, Norway},
 pages = {712--719},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1689599.1689692},
  doi       = {10.1109/CEC.2009.4983015},
  crossref  = {DBLP:conf/cec/2009},
 acmid = {1689692},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/McNabbGS09},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 abstract = {Particle Swarm Optimization (PSO) has typically been used with small swarms of about 50 particles. However, PSO is more efficiently parallelized with large swarms. We formally describe existing topologies and identify variations which are better suited to large swarms in both sequential and parallel computing environments. We examine the performance of PSO for benchmark functions with respect to swarm size and topology.
We develop and demonstrate a new PSO variant which leverages the unique strengths of large swarms. "Hearsay PSO" allows for information to flow quickly through the swarm, even with very loosely connected topologies. These loosely connected topologies are well suited to large scale parallel computing environments because they require very little communication between particles. We consider the case where function evaluations are expensive with respect to communication as well as the case where function evaluations are relatively inexpensive. We also consider a situation where local communication is inexpensive compared to external communication, such as multicore systems in a cluster.}
}

@inproceedings{ROI2008,
  title={Return on investment for active learning},
  author={Haertel, Robbie and Seppi, Kevin D and Ringger, Eric K and Carroll, James L},
  booktitle={Proceedings of the NIPS workshop on cost-sensitive learning},
  year={2008},
  abstract = {Active Learning (AL) can be defined as a selectively supervised learning protocol
intended to present those data to an oracle for labeling which will be most enlightening
for machine learning. While AL traditionally accounts for the value of the
information obtained, it often ignores the cost of obtaining the information thus
causing it to perform sub-optimally with respect to total cost. We present a framework
for AL that accounts for this cost and discuss optimality and tractability in
this framework. Using this framework we motivate Return On Investment (ROI),
a practical, cost-sensitive heuristic that can be used to convert existing algorithms
into cost-conscious active learners. We demonstrate the validity of ROI in a simulated
AL part-of-speech tagging task on the Penn Treebank in which ROI achieves
as high as a 73\% reduction in hourly cost over random selection.}
}

@inproceedings{ActiveLearningCost2008,
  author    = {Robbie Haertel and
               Eric K. Ringger and
               Kevin D. Seppi and
               James L. Carroll and
               Peter McClanahan},
  title     = {Assessing the Costs of Sampling Methods in Active Learning for Annotation},
  booktitle = {{ACL} 2008, Proceedings of the 46th Annual Meeting of the Association
               for Computational Linguistics, June 15-20, 2008, Columbus, Ohio, USA,
               Short Papers},
 series = {HLT-Short '08},
 location = {Columbus, Ohio},
  pages     = {65--68},
 numpages = {4},
  year      = {2008},
  crossref  = {DBLP:conf/acl/2008s},
  url       = {http://www.aclweb.org/anthology/P08-2017},
  timestamp = {Fri, 04 Jun 2010 13:14:24 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/acl/HaertelRSCM08},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 acmid = {1557708},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
 abstract = {Traditional Active Learning (AL) techniques
assume that the annotation of each datum costs
the same. This is not the case when annotating
sequences; some sequences will take
longer than others. We show that the AL technique
which performs best depends on how
cost is measured. Applying an hourly cost
model based on the results of an annotation
user study, we approximate the amount of time
necessary to annotate a given sentence. This
model allows us to evaluate the effectiveness
of AL sampling methods in terms of time
spent in annotation. We acheive a 77\% reduction
in hours from a random baseline to
achieve 96.5\% tag accuracy on the Penn Treebank.
More significantly, we make the case
for measuring cost in assessing AL methods.}
}
% url = {http://dl.acm.org/citation.cfm?id=1557690.1557708},

@inproceedings{ALUserStudy2008,
  author    = {Eric K. Ringger and
               Marc Carmen and
               Robbie Haertel and
               Kevin D. Seppi and
               Deryle Lonsdale and
               Peter McClanahan and
               James L. Carroll and
               Noel Ellison},
  title     = {Assessing the Costs of Machine-Assisted Corpus Annotation through
               a User Study},
  booktitle = {Proceedings of the International Conference on Language Resources
               and Evaluation, {LREC} 2008, 26 May - 1 June 2008, Marrakech, Morocco},
  year      = {2008},
  crossref  = {DBLP:conf/lrec/2008},
  url       = {http://www.lrec-conf.org/proceedings/lrec2008/summaries/832.html},
  timestamp = {Sat, 05 Jun 2010 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/lrec/RinggerCHSLMCE08},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{CorpusCreation2007,
  title={Modeling the annotation process for ancient corpus creation,” in Chatreˇsˇsar 2007},
  author={Carroll, James L and Haertel, Robbie and Mcclanahan, Peter and Ringger, Eric},
  booktitle={Charles University},
  year={2007},
  organization={Citeseer},
  abstract = {Abstract In corpus creation human annotation is expensive. Annotation costs can be 
minimized through machine learning and active learning, however there are many complex 
interactions among the machine learner, the active learning technique, the annotation cost, 
human annotation accuracy, the annotator user interface, and several other elements of the 
process. For example, we show that changing the way in which annotators are paid can 
drastically change the performance of active learning techniques. To date these ...}
}

@inproceedings{UtileOptimizer2007,
  author    = {Christopher K. Monson and
               Kevin D. Seppi and
               James L. Carroll},
  title     = {A Utile Function Optimizer},
  booktitle = {Proceedings of the {IEEE} Congress on Evolutionary Computation, {CEC}
               2007, 25-28 September 2007, Singapore},
  pages     = {1067--1074},
  year      = {2007},
  crossref  = {DBLP:conf/cec/2007},
  url       = {https://doi.org/10.1109/CEC.2007.4424588},
  doi       = {10.1109/CEC.2007.4424588},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/MonsonSC07},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{PSOUsingMR2007,
  author    = {Andrew W. McNabb and
               Christopher K. Monson and
               Kevin D. Seppi},
  title     = {Parallel {PSO} using MapReduce},
  booktitle = {Proceedings of the {IEEE} Congress on Evolutionary Computation, {CEC}
               2007, 25-28 September 2007, Singapore},
  pages     = {7--14},
  year      = {2007},
  crossref  = {DBLP:conf/cec/2007},
  url       = {https://doi.org/10.1109/CEC.2007.4424448},
  doi       = {10.1109/CEC.2007.4424448},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/McNabbMS07},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@inproceedings{MRPSO2007,
  author    = {Andrew W. McNabb and
               Christopher K. Monson and
               Kevin D. Seppi},
  title     = {{MRPSO:} MapReduce particle swarm optimization},
  booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} 2007, Proceedings,
               London, England, UK, July 7-11, 2007},
 series = {GECCO '07},
 location = {London, England},
 pages = {177--177},
 numpages = {1},
  year      = {2007},
  crossref  = {DBLP:conf/gecco/2007},
  url       = {http://doi.acm.org/10.1145/1276958.1276991},
  doi       = {10.1145/1276958.1276991},
 isbn = {978-1-59593-697-4},
 acmid = {1276991},
  timestamp = {Tue, 21 Aug 2007 12:31:32 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/McNabbMS07},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {optimization, parallelization, swarm intelligence},
 abstract = {In optimization problems involving large amounts of data, Particle Swarm Optimization (PSO) must be parallelized because individual function evaluations may take minutes or even hours. However, large-scale parallelization is difficult because programs must communicate efficiently, balance workloads and tolerate node failures. To address these issues, we present Map Reduce Particle Swarm Optimization(MRPSO), a PSO implementation based on Google's Map Reduce parallel programming model.}
}

@inproceedings{Hough2007,
  author    = {Neil Toronto and
               Bryan S. Morse and
               Dan Ventura and
               Kevin D. Seppi},
  title     = {The Hough Transform's Implicit Bayesian Foundation},
  booktitle = {Proceedings of the International Conference on Image Processing, {ICIP}
               2007, September 16-19, 2007, San Antonio, Texas, {USA}},
  pages     = {377--380},
  year      = {2007},
  crossref  = {DBLP:conf/icip/2007},
  url       = {https://doi.org/10.1109/ICIP.2007.4380033},
  doi       = {10.1109/ICIP.2007.4380033},
  timestamp = {Thu, 25 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icip/TorontoMVS07},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{FreeLunch2007,
  title={No-free-lunch and Bayesian optimality},
  author={Carroll, James L and Seppi, Kevin D},
  booktitle={IJCNN Workshop on Meta-Learning},
  year={2007},
  abstract={We take a Bayesian approach to the issues of bias, meta
bias, transfer, overfit, and No-Free-Lunch in the context of
supervised learning. If we accept certain relationships between
the function class, on training set data, and off training
set data, then a graphical model can be created that
represents the supervised learning problem. This graphical
model dictates a specific algorithm which will be the “optimal”
approach to learning the parameters of any given
function representation given the variable relationships.
Thus, there is an optimal technique for supervised learning.
We reconcile this idea of an optimal technique with the
ideas of No-Free-Lunch and show how these ideas relate to
the concepts of meta and transfer learning through hierarchical
versions of the graphical model.}
}

@inproceedings{BayesianCMAC2007,
  title={A bayesian CMAC for high assurance learning},
  author={Carroll, James L and Seppi, Kevin D},
  booktitle={Applications of Neural Networks in High-Assurance Systems, NASA-IJCNN Workshop},
  year={2007},
  abstract={We analyze the drawbacks to using ANNs in
high assurance systems and propose a solution based upon
a Bayesian approach with a specific network topology that
can be solved in closed form. The Bayesian approach leads
to better answers in the traditional sense, while also allowing
us to quantify risk and deal with it in a reasonable manner. We
demonstrate this approach on several synthetic functions and
the Abalone data set.}
}

@inproceedings{ALForPOS2007,
 author = {Ringger, Eric and McClanahan, Peter and Haertel, Robbie and Busby, George and Carmen, Marc and Carroll, James and Seppi, Kevin and Lonsdale, Deryle},
 title = {Active Learning for Part-of-speech Tagging: Accelerating Corpus Annotation},
 booktitle = {Proceedings of the Linguistic Annotation Workshop},
 series = {LAW '07},
 year = {2007},
 location = {Prague, Czech Republic},
 pages = {101--108},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1642059.1642075},
 acmid = {1642075},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
 abstract = {In the construction of a part-of-speech annotated corpus, we are constrained by a fixed budget. A fully annotated corpus is required, but we can afford to label only a subset. We train a Maximum Entropy Markov Model tagger from a labeled subset and automatically tag the remainder. This paper addresses the question of where to focus our manual tagging efforts in order to deliver an annotation of highest quality. In this context, we find that active learning is always helpful. We focus on Query by Uncertainty (QBU) and Query by Committee (QBC) and report on experiments with several baselines and new variations of QBC and QBU, inspired by weaknesses particular to their use in this application. Experiments on English prose and poetry test these approaches and evaluate their robustness. The results allow us to make recommendations for both types of text and raise questions that will lead to further inquiry.}
}

@inproceedings{ProfitMax2006,
  author    = {Nghia Tran and
               Christophe G. Giraud{-}Carrier and
               Kevin D. Seppi and
               Sean C. Warnick},
  title     = {Cooperation-based Clustering for Profit-maximizing Organizational
               Design},
  booktitle = {Proceedings of the International Joint Conference on Neural Networks,
               {IJCNN} 2006, part of the {IEEE} World Congress on Computational Intelligence,
               {WCCI} 2006, Vancouver, BC, Canada, 16-21 July 2006},
  pages     = {1813--1817},
  year      = {2006},
  crossref  = {DBLP:conf/ijcnn/2006},
  url       = {https://doi.org/10.1109/IJCNN.2006.246899},
  doi       = {10.1109/IJCNN.2006.246899},
  timestamp = {Fri, 26 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ijcnn/TranGSW06},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{AdaptiveDiversity2006,
  author    = {Christopher K. Monson and
               Kevin D. Seppi},
  title     = {Adaptive diversity in {PSO}},
  booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} 2006, Proceedings,
               Seattle, Washington, USA, July 8-12, 2006},
 series = {GECCO '06},
 location = {Seattle, Washington, USA},
  pages     = {59--66},
 numpages = {8},
  year      = {2006},
  crossref  = {DBLP:conf/gecco/2006},
  url       = {http://doi.acm.org/10.1145/1143997.1144006},
  doi       = {10.1145/1143997.1144006},
 isbn = {1-59593-186-4},
 acmid = {1144006},
  timestamp = {Fri, 29 Sep 2006 14:35:19 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/MonsonS06},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptation, optimization, swarm intelligence},
 abstract = {Spatial Extension PSO (SEPSO) and Attractive-Repulsive PSO (ARPSO) are methods for artificial injection of diversity into particle swarm optimizers that are intended to encourage converged swarms to engage in exploration. While simple to implement, effective when tuned correctly, and benefiting from intuitive appeal, SEPSO behavior can be improved by adapting its radius and bounce parameters in response to collisions. In fact, adaptation can allow SEPSO to compete with and outperform ARPSO. The adaptation strategies presented here are simple to implement, easy to tune, and retain SEPSO's intuitive appeal.}
}

@inproceedings{PSOPricing2006,
  author    = {Patrick B. Mullen and
               Christopher K. Monson and
               Kevin D. Seppi and
               Sean C. Warnick},
  title     = {Particle Swarm Optimization in Dynamic Pricing},
  booktitle = {{IEEE} International Conference on Evolutionary Computation, {CEC}
               2006, part of {WCCI} 2006, Vancouver, BC, Canada, 16-21 July 2006},
  pages     = {1232--1239},
  year      = {2006},
  crossref  = {DBLP:conf/cec/2006},
  url       = {https://doi.org/10.1109/CEC.2006.1688450},
  doi       = {10.1109/CEC.2006.1688450},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/MullenMSW06},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@INPROCEEDINGS{EconomicSystem2005, 
author={N. Tran and W. Weyerman and C. Giraud-Carrier and K. Seppi and S. Warnick and R. Johnson}, 
booktitle={Proceedings of 2005 IEEE Conference on Control Applications, 2005. CCA 2005.}, 
title={Studies in the Dynamics of Economic Systems}, 
year={2005}, 
pages={861-866}, 
abstract={This paper demonstrates the utility of systems and control theory in the analysis of economic systems. Two applications demonstrate how the analysis of simple dynamic models sheds light on important practical problems. The first problem considers the design of a retail laboratory, where the small gain theorem enables the falsification of pricing policies. The second problem explores industrial organization using the equilibria of profit-maximizing dynamics to quantify the percentage of a firm's profits due strictly to the cooperative effects among its products. This "value of cooperation" suggests an important measure for both organizational and antitrust applications}, 
keywords={control theory;economics;profitability;control theory;economic system dynamics;industrial organization;pricing policy falsification;profit-maximizing dynamics;Application software;Cities and towns;Computer science;Control theory;Feedback;Intelligent systems;Laboratories;Power generation economics;Pricing;Rivers}, 
doi={10.1109/CCA.2005.1507237}, 
ISSN={1085-1992}, 
month={Aug},}

@conference{WebsitePricing2005,
author	= "P. Mullen and K. Seppi and S. Warnick",
title	= "Dynamic Pricing on Commercial Websites: A Computationally Intensive Approach",
    booktitle = {Proceedings of the Fourth International Conference on Computational Intelligence in Economics and Finance at the Eighth Joint Conference on Information Sciences},
address	= "Salt Lake City",
year	= 2005,
}

@conference{SmallGain2005,
author	= "N. Tran and C. Giraud-Carrier and K. Seppi and S. Warnick",
title	= "Implications of the Small Gain Theorem in the Design of an Economic Laboratory",
    booktitle = {Proceedings of the Fourth International Conference on Computational Intelligence in Economics and Finance at the Eighth Joint Conference on Information Sciences},
address	= "Salt Lake City, UT",
year	= 2005,
}

@conference{Cooperation2005,
    author = {N. Tran and D. West and C. Giraud-Carrier and K. Seppi and S. Warnick and R. Johnson},
    title = {The value of cooperation within a profit maximizing organization},
    booktitle = {Proceedings of the Fourth International Conference on Computational Intelligence in Economics and Finance at the Eighth Joint Conference on Information Sciences},
    pages = {1017-1020},
address	= "Salt Lake City, UT",
    year = {2005}
}

@inproceedings{Homomorphic2005,
  author    = {Christopher K. Monson and
               Kevin D. Seppi},
  title     = {Linear equality constraints and homomorphous mappings in {PSO}},
  booktitle = {Proceedings of the {IEEE} Congress on Evolutionary Computation, {CEC}
               2005, 2-4 September 2005, Edinburgh, {UK}},
  pages     = {73--80},
  year      = {2005},
month={Sept},
  crossref  = {DBLP:conf/cec/2005},
  url       = {https://doi.org/10.1109/CEC.2005.1554669},
  doi       = {10.1109/CEC.2005.1554669},
ISSN={1089-778X}, 
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/cec/MonsonS05},
  bibsource = {dblp computer science bibliography, http://dblp.org},
keywords={particle swarm optimisation;homomorphous mapping;linear equality constraints;lower-dimensional problem;particle swarm optimisation algorithm;unconstrained optimization algorithm;Algorithm design and analysis;Computer science;Constraint optimization;Equations;Particle swarm optimization;Subspace constraints;Support vector machines;Transforms}, 
abstract={We present a homomorphous mapping that converts problems with linear equality constraints into fully unconstrained and lower-dimensional problems for optimization with PSO. This approach, in contrast with feasibility preservation methods, allows any unconstrained optimization algorithm to be applied to a problem with linear equality constraints, making available tools that are known to be effective and simplifying the process of choosing an optimizer for these kinds of constrained problems. The application of some PSO algorithms to a problem that has undergone the mapping presented here is shown to be more effective and more consistent than other approaches to handling linear equality constraints in PSO}, 
}

@inproceedings{PSOBias2005,
  author    = {Christopher K. Monson and
               Kevin D. Seppi},
  title     = {Exposing origin-seeking bias in {PSO}},
  booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} 2005, Proceedings,
               Washington DC, USA, June 25-29, 2005},
 series = {GECCO '05},
 location = {Washington DC, USA},
  pages     = {241--248},
 numpages = {8},
  year      = {2005},
  crossref  = {DBLP:conf/gecco/2005},
  url       = {http://doi.acm.org/10.1145/1068009.1068045},
  doi       = {10.1145/1068009.1068045},
 isbn = {1-59593-010-8},
 acmid = {1068045},
  timestamp = {Fri, 10 Feb 2006 00:00:00 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/MonsonS05a},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {initialization bias, optimization, swarm intelligence},
 abstract = {We discuss testing methods for exposing origin-seeking bias in PSO motion algorithms. The strategy of resizing the initialization space, proposed by Gehlhaar and Fogel and made popular in the PSO context by Angeline, is shown to be insufficiently general for revealing an algorithm's tendency to focus its efforts on regions at or near the origin. An alternative testing method is proposed that reveals problems with PSO motion algorithms that are not visible when merely resizing the initialization space.}
}

@inproceedings{BayesianPSO2005,
 author = {Monson, Christopher K. and Seppi, Kevin D.},
 title = {Bayesian Optimization Models for Particle Swarms},
 booktitle = {Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '05},
 year = {2005},
 isbn = {1-59593-010-8},
 location = {Washington DC, USA},
 pages = {193--200},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1068009.1068039},
  crossref  = {DBLP:conf/gecco/2005},
 doi = {10.1145/1068009.1068039},
 acmid = {1068039},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mathematical models, optimization, swarm intelligence},
 abstract = {We explore the use of information models as a guide for the development of single objective optimization algorithms, giving particular attention to the use of Bayesian models in a PSO context. The use of an explicit information model as the basis for particle motion provides tools for designing successful algorithms. One such algorithm is developed and shown empirically to be effective. Its relationship to other popular PSO algorithms is explored and arguments are presented that those algorithms may be developed from the same model, potentially providing new tools for their analysis and tuning.}
}

@INPROCEEDINGS{LearningLibraries2005, 
author={J. L. Carroll and K. Seppi}, 
booktitle={Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.}, 
title={Task similarity measures for transfer in reinforcement learning task libraries}, 
year={2005}, 
volume={2}, 
pages={803-808 vol. 2}, 
abstract={Recent research in task transfer and task clustering has necessitated the need for task similarity measures in reinforcement learning. Determining task similarity is necessary for selective transfer where only information from relevant tasks and portions of a task are transferred. Which task similarity measure to use is not immediately obvious. It can be shown that no single task similarity measure is uniformly superior. The optimal task similarity measure is dependent upon the task transfer method being employed. We define similarity in terms of tasks, and propose several possible task similarity measures, dT, dP, dQ, and dR which are based on the transfer time, policy overlap, Q-values, and reward structure respectively. We evaluate their performance in three separate experimental situations.}, 
keywords={learning (artificial intelligence);reinforcement learning task libraries;task clustering;task similarity measures;task transfer;Computer science;Degradation;Gain measurement;Humans;Learning;Libraries;Measurement standards;Time measurement}, 
doi={10.1109/IJCNN.2005.1555955}, 
ISSN={2161-4393}, 
month={July},}

@inproceedings{Schwartz2005,
  author    = {David Wingate and
               Nathaniel Powell and
               Quinn Snell and
               Kevin D. Seppi},
  title     = {Prioritized Multiplicative Schwarz Procedures for Solving Linear Systems},
  booktitle = {19th International Parallel and Distributed Processing Symposium {IPDPS}
               2005 / Abstracts Proceedings, 4-8 April 2005, Denver, CO,
               {USA}},
 series = {IPDPS '05},
 pages = {8.1--},
  year      = {2005},
  crossref  = {DBLP:conf/ipps/2005},
  url       = {https://doi.org/10.1109/IPDPS.2005.359},
  doi       = {10.1109/IPDPS.2005.359},
 isbn = {0-7695-2312-9},
 acmid = {1054469},
  timestamp = {Wed, 24 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ipps/WingatePSS05},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 abstract = {We describe a new algorithm designed to quickly and robustly solve general linear problems of the form Ax = b. We describe both serial and parallel versions of the algorithm, which can be considered a prioritized version of an alternating multiplicative Schwarz procedure. We also adopt a general view of alternating multiplicative Schwarz procedures which motivates their use on arbitrary problems (even which may not have arisen from problems that are naturally decomposable) by demonstrating that, even in a serial context, algorithms should use many, many partitions to accelerate convergence; having such an over-partitioned system also allows easy parallelization of the algorithm, and scales extremely well. We present extensive empirical evidence, which demonstrates that our algorithm, with a companion subsolver, can often improve performance by several orders of magnitude over the subsolver by itself and over other algorithms.}
}

@article{Jumpstarting2004,
  title={Jumpstarting Phylogenetic Analysis},
  author={Clement, Mark J and Crandall, Keith A and Seppi, Kevin D and Snell, Quinn O},
  year={2004},
  publisher={Biotechnology and Bioinformatics Symposium(BIOT)},
  abstract = { When a new epidemic strikes, it is often important to determine the relationship between the current organism and others that have been successfully treated previously. The phylogenetic analysis problem generates the most likely family tree for a group of organisms based on DNA sequence data. This process can take a prohibitively long period of time with current algorithms. If trees resulting from prior searches are used to seed the search, correct trees can be found much more quickly. This jumpstarting algorithm can generate superior phylogenetic solutions much more quickly than existing algorithms. }
}

@inproceedings{P3VI2004,
  author    = {David Wingate and
               Kevin D. Seppi},
 title = {P3VI: A Partitioned, Prioritized, Parallel Value Iterator},
  booktitle = {Machine Learning, Proceedings of the Twenty-first International Conference
               {ICML} 2004, Banff, Alberta, Canada, July 4-8, 2004},
 series = {ICML '04},
 location = {Banff, Alberta, Canada},
  year      = {2004},
 pages = {109--},
  crossref  = {DBLP:conf/icml/2004},
  url       = {http://doi.acm.org/10.1145/1015330.1015440},
  doi       = {10.1145/1015330.1015440},
 isbn = {1-58113-838-5},
 acmid = {1015440},
  timestamp = {Mon, 22 Oct 2007 13:54:01 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icml/WingateS04},
  bibsource = {dblp computer science bibliography, http://dblp.org},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Asynchronous dynamic programming, reinforcement learning, value iteration},
 abstract = {We present an examination of the state-of-the-art for using value iteration to solve large-scale discrete Markov Decision Processes. We introduce an architecture which combines three independent performance enhancements (the intelligent prioritization of computation, state partitioning, and massively parallel processing) into a single algorithm. We show that each idea improves performance in a different way, meaning that algorithm designers do not have to trade one improvement for another. We give special attention to parallelization issues, discussing how to efficiently partition states, distribute partitions to processors, minimize message passing and ensure high scalability. We present experimental results which demonstrate that this approach solves large problems in reasonable time.}
}

@inproceedings{KalmanSwarm2004,
  author    = {Christopher K. Monson and
               Kevin D. Seppi},
  title     = {The Kalman Swarm: {A} New Approach to Particle Motion in Swarm Optimization},
  booktitle = {Genetic and Evolutionary Computation - {GECCO} 2004, Genetic and Evolutionary
               Computation Conference, Seattle, WA, USA, June 26-30, 2004, Proceedings,
               Part {I}},
  pages     = {140--150},
  year      = {2004},
  crossref  = {DBLP:conf/gecco/2004-1},
  url       = {https://doi.org/10.1007/978-3-540-24854-5_13},
  doi       = {10.1007/978-3-540-24854-5_13},
  timestamp = {Tue, 30 May 2017 12:57:44 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/gecco/MonsonS04},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{ImprovingKalmanSwarm2008,
  title={Improving on the Kalman Swarm Extracting Its Essential Characteristics},
  author={Christopher K. Monson and Kevin D. Seppi},
  booktitle = {Genetic and Evolutionary Computation - {GECCO} 2004, Late Breaking Papers},
  location = {Seattle, WA, USA},
  year={2008}
}

@inproceedings{MDPCache2004,
  title={Cache performance of priority metrics for mdp solvers},
  author={Wingate, David and Seppi, Kevin D},
  booktitle={AAAI Workshop on Learning and Planning in Markov Processes},
  pages={103--106},
  year={2004},
  url = {http://www.aaai.org/Papers/Workshops/2004/WS-04-08/WS04-08-018.pdf},
  abstract = {As algorithms scale to solve larger and larger MDPs, it becomes
impossible to store all of the model information of the
MDP and the supporting data structures of the algorithm in
RAM. This motivates the study of the disk-based-cache ef-
ficiency of solution algorithms. We contrast the cache effi-
ciency of normal value iteration with that of the P-EVA algorithm,
and introduce the concept of “intrinsic cacheability.”
We concentrate on prioritized solution methods, and demonstrate
that the choice of priority metric greatly affects cache
behavior. Experimental results indicate that the best priority
metric allows problems which are four times larger than
available RAM to be solved effectively.}
}

@inproceedings{TaskLocalization2004,
  author    = {James L. Carroll and
               Kevin D. Seppi},
  title     = {A Bayesian technique for task localization in multiple goal Markov
               decision processes},
  booktitle = {Proceedings of the 2004 International Conference on Machine Learning
               and Applications - {ICMLA} 2004, 16-18 December 2004, Louisville,
               KY, {USA.}},
  pages     = {49--56},
  year      = {2004},
  crossref  = {DBLP:conf/icmla/2004},
  url       = {https://doi.org/10.1109/ICMLA.2004.1383493},
  doi       = {10.1109/ICMLA.2004.1383493},
  timestamp = {Fri, 19 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icmla/CarrollS04},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{VariableResolution2004,
  author    = {Christopher K. Monson and
               David Wingate and
               Kevin D. Seppi and
               Todd S. Peterson},
  title     = {Variable resolution discretization in the joint space},
  booktitle = {Proceedings of the 2004 International Conference on Machine Learning
               and Applications - {ICMLA} 2004, 16-18 December 2004, Louisville,
               KY, {USA.}},
  pages     = {449--455},
  year      = {2004},
  crossref  = {DBLP:conf/icmla/2004},
  url       = {https://doi.org/10.1109/ICMLA.2004.1383549},
  doi       = {10.1109/ICMLA.2004.1383549},
  timestamp = {Fri, 19 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icmla/MonsonWSP04},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{EfficientVI2003,
  author    = {David Wingate and
               Kevin D. Seppi},
  title     = {Efficient Value Iteration Using Partitioned Models},
  booktitle = {Proceedings of the 2003 International Conference on Machine Learning
               and Applications - {ICMLA} 2003, June 23-24, 2003, Los Angeles, California,
               {USA.}},
  pages     = {53--59},
  year      = {2003},
  crossref  = {DBLP:conf/icmla/2003},
  timestamp = {Mon, 28 May 2007 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icmla/WingateS03},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{TaskClustering2003,
  author    = {James L. Carroll and
               Todd S. Peterson and
               Kevin D. Seppi},
  title     = {Reinforcement Learning Task Clustering},
  booktitle = {Proceedings of the 2003 International Conference on Machine Learning
               and Applications - {ICMLA} 2003, June 23-24, 2003, Los Angeles, California,
               {USA.}},
  pages     = {66--72},
  year      = {2003},
  crossref  = {DBLP:conf/icmla/2003},
  timestamp = {Mon, 22 Dec 2008 00:00:00 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icmla/CarrollPS03},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

% Not using this, important corrections in the Journal version
%
@INPROCEEDINGS{BayesianModelChecking2004, 
  author    = {Kevin D. Seppi and
               Michael D. Jones and
               Peter Lamborn},
booktitle={Proceedings. Fourth International Conference on Application of Concurrency to System Design, 2004. ACSD 2004.}, 
location = {Hamilton, Canada},
title={Guided model checking with a Bayesian meta-heuristic}, 
year={2004}, 
pages={217-226}, 
  crossref  = {DBLP:conf/acsd/2004},
  url       = {https://doi.org/10.1109/CSD.2004.1309134},
  doi       = {10.1109/CSD.2004.1309134},
  timestamp = {Thu, 25 May 2017 01:00:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/acsd/SeppiJL04},
  bibsource = {dblp computer science bibliography, http://dblp.org},
abstract={This work presents a formal verification algorithm for finding errors in models of complex concurrent systems. The algorithm improves explicit guided model checking by applying the empirical Bayes method to revise heuristic estimates of the distance from a given state to an error state. Guided search using the revised estimates finds errors with less search effort than the original estimates.}, 
keywords={Bayes methods;concurrency control;formal verification;search problems;Bayes method;Bayesian metaheuristic;complex concurrent systems;error state;formal verification;guided model checking;guided search;heuristic estimates;Bayesian methods;Computer errors;Computer science;Concurrent computing;Cost function;Formal verification;Protocols;Random variables;State estimation;Statistical analysis}, 
doi={10.1109/CSD.2004.1309134}, 
month={June},}

%----------------------------------------
% Not peer reviewed:

@article{BMCCEMS1998,
  author  = {D. Spuler, J. Kushner and K. Seppi}, 
  title   = {Empowering CEMS via Agent Technology},
  journal = {BMC Tech News},
  year    = 1998,
  month   = 7,
  note    = {July-Sept}, 
}

@techreport{Persona1993,
  author       = {M. Dockter, J. Farber and K. Seppi}, 
  title        = {Facility for the Intelligent Selection of Information Objects (PERSONA)},
  institution  = {IBM Santa Teresa Lab Technical Report 03.459},
  year         = 1993,
  month = {January}
}

@techreport{Classification1992,
  author       = {M. Dockter, J. Farber and K. Seppi}, 
  title        = {Method for Storing and Retrieving Heterogeneous Classification Systems},
  institution  = {IBM Santa Teresa Lab Technical Report 03.447},
  year         = 1992,
  month = {April}
}

@techreport{Grinding1992,
  author       = {M. Dockter, J. Farber and K. Seppi}, 
  title        = {Grinding: A Facility for the Automatic Association of Heterogeneous Objects},
  institution  = {IBM Santa Teresa Lab Technical Report 03.459},
  year         = 1992,
  month        = {April},
}

@techreport{KMC1992,
  author       = {M. Dockter, A. Peterson and K. Seppi}, 
  title        = {Knowledge Mining Center Phase One: A Computer Supported Collaborative Workspace},
  institution  = {IBM Santa Teresa Lab Technical Report 03.434},
  year         = 1992,
  month        = {May},
}

@conference{SXLISP1991,
  author       = {C. Christiansen, J. Glosup, C. Morris and K. Seppi}, 
  title        = {An Overview of the 'S' and 'XLISP-STAT' Statistical Programming Languages (Updated)},
  booktitle    = {The Proceedings of the IBM Reliability \& Applied Statistics ITL},
  year         = 1991,
  location      = {IBM East Fishkill, New York},
  month        = {May 13-16},
  organization = {IBM Reliability \& Applied Statistics ITL},
}

@techreport{SelectingAlgorithms1990,
  author       = {K. Seppi}, 
  title        = {Selecting Algorithms in the Presence of Uncertainty},
  institution  = {IBM Technical Disclosures Bulletin},
  year         = 1990,
}

@techreport{SXLISP1990,
  author       = {C. Christiansen, J. Glosup, C. Morris and K. Seppi}, 
  title        = {An Overview of the 'S' and 'XLISP-STAT' Statistical Programming Languages},
  institution  = {University of Texas Center for Statistical Sciences Technical Report \#89},
  year         = 1990,
  note         = {Also presented at the Statistical Computation Conference at the University of Texas, May 18 1990}
}

@techreport{QueryOptimization1989,
  author       = {K. Seppi, J. Barnes and C. Morris}, 
  title        = {A Bayesian Approach to Query Optimization in Large Scale Data Bases},
  institution  = {Graduate Program in Operations Research Technical Report OR89-19,
The University of Texas at Austin. Austin, Texas},
  year         = 1989,
  month        = {December},
}

@techreport{IndexDelete1989,
  author       = {K. Seppi and D. Haderle}, 
  title        = {Index Mass Delete},
  institution  = {IBM Technical Disclosures Bulletin},
  year         = 1989,
  pages         = {454--455}
}

@techreport{NonRootLocking1989,
  author       = {K. Seppi, T. Malkemus, R. Crus and D. Haderle}, 
  title        = {Conditional Non-root Locking},
  institution  = {IBM Technical Disclosures Bulletin},
  year         = 1989,
  pages         = {57-58},
  month        = {August},
}

%----------------------------------------------
% PATENTS

@Patent{DataConsistency2000,
  title={Enterprise data movement system and method which maintains and compares edition levels for consistency of replicated data},
  author={Martin, James L and Sirjani, Abolfazl and Seppi, Kevin D and Keeler, Lisa S},
  year={2000},
  month=feb # "~22",
  number={US Patent 6,029,178}
}

@Patent{DataMove2000,
  title={Enterprise data movement system and method including opportunistic performance of utilities and data move operations for improved efficiency},
  author={Martin, James L and Sirjani, Abolfazl and Seppi, Kevin D and Keeler, Lisa S},
  year={2000},
  month=mar # "~7",
  number={US Patent 6,035,307}
}

@Patent{DataPropagation2000,
  title={Enterprise data movement system and method which performs data load and changed data propagation operations},
  author={Martin, James L and Sirjani, Abolfazl and Seppi, Kevin D and Keeler, Lisa S},
  year={2000},
  month=jan # "~18",
  number={US Patent 6,016,501}
}

@Patent{ObjectSelection2001,
  title={Facility for the intelligent selection of information objects},
  author={Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={2001},
  month=mar # "~27",
  number={US Patent 6,208,989}
}

@Patent{ConnectionServer1997,
  title={Facility for the storage and management of connection (connection server)},
  author={Dockter, Michael J and Farber, Joel F and Seppi, Kevin D and Tolleson, David W},
  year={1997},
  month=nov # "~11",
  number={US Patent 5,687,367}
}

@Patent{BlockTag1997,
  title={System and method for block generation of monotonic globally unique tag values, where restart tag value due to failure starts at highest value of previously generated tag values},
  author={Dockter, Michael Jon and Farber, Joel Frank and Pauser, Michael Leon and Seppi, Kevin Darrell and Tolleson, David Wayne},
  year={1997},
  month=jun # "~17",
  number={US Patent 5,640,608}
}

@Patent{Association1998,
  title={Method for association of heterogeneous information},
  author={Bingham, Ronald E and Campbell, Harry R and Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={1998},
  month=apr # "~28",
  number={US Patent 5,745,895}
}

@Patent{Persona1998,
  title={Facility for the intelligent selection of information objects (persona)},
  author={Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={1998},
  month=dec # "~29",
  number={US Patent 5,854,923}
}

@Patent{Storing1997,
  title={Storing and retrieving heterogeneous classification systems utilizing globally unique identifiers},
  author={Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={1997},
  month=oct # "~14",
  number={US Patent 5,678,038}
}

@Patent{Generation1997,
  title={Generation and storage of connections between objects in a computer network},
  author={Dockter, Michael J and Farber, Joel F and Gordon, Jeffrey D and Seppi, Kevin D and Kleewein, James C},
  year={1997},
  month=mar # "~4",
  number={US Patent 5,608,900}
}

@Patent{Managment1996,
  title={Facility for the generic storage and management of multimedia objects},
  author={Bingham, Ronald E and Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={1996},
  month=sep # "~17",
  number={US Patent 5,557,790}
}

@Patent{Communications1995,
  title={Communications interface employing unique tags which enable a destination to decode a received message structure},
  author={Dockter, Michael J and Farber, Joel F and Kleewein, James C and Seppi, Kevin D and Tolleson, David W},
  year={1995},
  month=jul # "~18",
  number={US Patent 5,434,978}
}

@Patent{Synchronization1995,
  title={System and method for synchronization of multimedia streams},
  author={Dockter, Michael J and Haug, Charles L and Seppi, Kevin D},
  year={1995},
  month=may # "~30",
  number={US Patent 5,420,801}
}

@Patent{Tokens1995,
  title={Computerized system for representing data items using token identifiers},
  author={Bingham, Ronald E and Dockter, Michael J and Farber, Joel F and Seppi, Kevin D},
  year={1995},
  month=may # "~9",
  number={US Patent 5,414,841}
}

